{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'SchedulerType' from 'transformers' (/Users/lihaonan/miniconda3/lib/python3.8/site-packages/transformers/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-5c3c2cebe616>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CUDA_VISIBLE_DEVICES\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"1\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mLAMB_Exec\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/mygit/LAMB/src/LAMB_Exec.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mData\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mModel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSchedulerType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_seed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/mygit/LAMB/src/Data.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m from transformers import (\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mAdamW\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mAutoConfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'SchedulerType' from 'transformers' (/Users/lihaonan/miniconda3/lib/python3.8/site-packages/transformers/__init__.py)"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "from LAMB_Exec import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'argparse' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-c0293c533f15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mArgumentParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'TourQue Executor'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_argument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--batch_size\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_argument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--gradient_accumulation_steps\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_argument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--seed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'argparse' is not defined"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='TourQue Executor')\n",
    "\n",
    "parser.add_argument(\"--batch_size\", type=int, default=4)\n",
    "parser.add_argument(\"--gradient_accumulation_steps\", type=int, default=8)\n",
    "parser.add_argument(\"--seed\", type=int, default=42)\n",
    "parser.add_argument('--loss', type=str, default=\"nll\")\n",
    "parser.add_argument(\"--margin\", type=float, default=1.0) # if use margin ranking loss\n",
    "parser.add_argument(\"--lr\", type=float, default=5e-5)\n",
    "parser.add_argument(\"--lr_scheduler_type\", type=SchedulerType, default=\"linear\",\n",
    "        choices=[\"linear\", \"cosine\", \"cosine_with_restarts\", \"polynomial\", \"constant\", \"constant_with_warmup\"])\n",
    "parser.add_argument(\"--num_warmup_steps\", type=float, default=0)\n",
    "parser.add_argument(\"--dropout\", type=float, default=0.2)\n",
    "parser.add_argument(\"--num_training_steps\", type=int, default=7100)\n",
    "# contrastive\n",
    "parser.add_argument(\"--samples_per_qa\", type=int, default=5)\n",
    "parser.add_argument(\"--hard_negatives_per_qa\", type=int, default=1)\n",
    "parser.add_argument(\"--score_method\", type=str, default=\"dot\", choices=['dot','bilinear','cosine'])\n",
    "# textual module\n",
    "parser.add_argument(\"--transformer_model\", type=str, default='distilbert-base-uncased')\n",
    "parser.add_argument(\"--max_question_length\", type=int, default=384)\n",
    "parser.add_argument(\"--max_entity_length\", type=int, default=512)\n",
    "parser.add_argument(\"--n_cluster_reviews\", type=int, default=0)\n",
    "parser.add_argument(\"--encode_entity_name\", action=\"store_true\")\n",
    "# location module\n",
    "parser.add_argument(\"--location\", action=\"store_true\")\n",
    "parser.add_argument(\"--max_locations\", type=int, default=5)\n",
    "# distance module\n",
    "parser.add_argument(\"--distance\", action=\"store_true\")\n",
    "parser.add_argument(\"--haversine_distance\", action=\"store_true\")\n",
    "parser.add_argument(\"--dist_weight\", type=float, default=0.2)\n",
    "# test\n",
    "parser.add_argument(\"--test_mode\", action=\"store_true\")\n",
    "parser.add_argument(\"--debug\", action=\"store_true\")\n",
    "parser.add_argument(\"--test_batch_size\", type=int, default=16)\n",
    "parser.add_argument(\"--batch_size_save_entity\", type=int, default=24)\n",
    "parser.add_argument(\"--save_every\", type=int, default=100)\n",
    "parser.add_argument(\"--save_after\", type=int, default=900)\n",
    "parser.add_argument(\"--eval_type\", default='std', choices=['std','std+','random','random+','full'])\n",
    "# other\n",
    "parser.add_argument(\"--use_wandb\", action=\"store_true\")\n",
    "parser.add_argument('--output_dir', type=str, default=\"\")\n",
    "parser.add_argument('--data_dir', type=str, default=\"/Users/haonanl5/Downloads/tourqa/data/\")\n",
    "parser.add_argument('--test_file', type=str, default=\"test_loc.json\")\n",
    "parser.add_argument('--train_file', type=str, default=\"train_loc.json\")\n",
    "parser.add_argument('--valid_file', type=str, default=\"valid_loc.json\")\n",
    "parser.add_argument(\"--id_file\", type=str,default=\"entity_id.json\")\n",
    "parser.add_argument(\"--emb_file\", type=str,default=\"entity_emb.np\")\n",
    "parser.add_argument(\"--knowledge_file\", type=str,default=\"TourQue_Knowledge_Cluster.json\")\n",
    "parser.add_argument(\"--cities_lat_long_file\", type=str, default=\"final_cities_lat_long.json\")\n",
    "\n",
    "\n",
    "opts = parser.parse_args('  \\\n",
    "    --loss nll \\\n",
    "    --score_method dot \\\n",
    "    --seed 42 \\\n",
    "    --eval_type std \\\n",
    "\t--batch_size 2 \\\n",
    "\t--gradient_accumulation_steps 8 \\\n",
    "    --max_locations 5 \\\n",
    "    --dist_weight 0.1 \\\n",
    "\t--samples_per_qa 3 \\\n",
    "    --hard_negatives_per_qa 0 \\\n",
    "--data_dir /home/haonanl5/tourqa/data'.split())\n",
    "\n",
    "\n",
    "opts = init_args(opts)\n",
    "\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(asctime)s - %(message)s',\n",
    "                    datefmt='%m/%d/%Y %I:%M:%S',\n",
    "                    handlers=[\n",
    "                        logging.FileHandler(opts.log_file),\n",
    "                        logging.StreamHandler()\n",
    "                    ])\n",
    "\n",
    "# Load Data\n",
    "data_obj = Lamb_Data(opts=opts)\n",
    "prep = Lamb_Prepare(opts, data_obj)\n",
    "network = Lamb(opts)\n",
    "network.load_state_dict(torch.load(os.path.join(opts.output_dir,f'{opts.prefix}.weights')))\n",
    "network.to(opts.device)\n",
    "\n",
    "# test_data = data_obj.load_data_from_files(opts.test_file, training=False, debug=opts.debug)\n",
    "#test(opts, data_obj, prep, network, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2': 2}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = {'1':1,'2':2}\n",
    "a.pop('1')\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Training, Validation and Test Data from files.\n",
      "Loading Samples from file: /home/haonanl5/tourqa/data/TourQue_QA_Pairs/train_loc.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 21396/21396 [00:02<00:00, 9329.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expand samples with candidates.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 21105/21105 [00:00<00:00, 24051.75it/s]\n",
      "05/21/2022 10:35:40 - ***** Running training *****\n",
      "05/21/2022 10:35:40 -   Num examples = 21105\n",
      "05/21/2022 10:35:40 -   Instantaneous batch size per device = 2\n",
      "05/21/2022 10:35:40 -   Gradient Accumulation steps = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Generation took: 3.8893392086029053 seconds. QA Pairs/Posts: 21105\n",
      "******\n",
      "Data sample 0: question -- In three weeks I will be attending a conference at the Marriott downtown Mag Mile. We have a budge of $25 a day for food. We are all teachers. Any CHEAP suggestions for restaurants/café for the three days we will stay there. I like mainly American Style dining (pizza, sandwiches, breakfast fare, pasta, pastry) not a fan of sea food or spicy food. We will not have a car and in most cases fairly limited time for meals. Any and all suggestions greatly appreciated.\n",
      "Data sample 0: answer_entity_id -- 2_R_9967\n",
      "Data sample 0: all_answer_entities -- {'2_R_9967', '2_R_2631'}\n",
      "Data sample 0: all_answer_entity_list -- ['2_R_2631', '2_R_9967']\n",
      "Data sample 0: candidates (subset) -- ['10_H_76440', '22_R_3075']\n",
      "******\n",
      "\n",
      "******\n",
      "Data sample 1: question -- In three weeks I will be attending a conference at the Marriott downtown Mag Mile. We have a budge of $25 a day for food. We are all teachers. Any CHEAP suggestions for restaurants/café for the three days we will stay there. I like mainly American Style dining (pizza, sandwiches, breakfast fare, pasta, pastry) not a fan of sea food or spicy food. We will not have a car and in most cases fairly limited time for meals. Any and all suggestions greatly appreciated.\n",
      "Data sample 1: answer_entity_id -- 2_R_2631\n",
      "Data sample 1: all_answer_entities -- {'2_R_9967', '2_R_2631'}\n",
      "Data sample 1: all_answer_entity_list -- ['2_R_2631', '2_R_9967']\n",
      "Data sample 1: candidates (subset) -- ['12_R_15950', '18_R_9237']\n",
      "******\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/21/2022 10:35:42 - Global step: 1, Loss: 15.878191590309143\n",
      "05/21/2022 10:35:44 - Global step: 2, Loss: 13.151074588298798\n",
      "05/21/2022 10:35:46 - Global step: 3, Loss: 9.077831208705902\n",
      "05/21/2022 10:35:49 - Global step: 4, Loss: 4.437207579612732\n",
      "05/21/2022 10:35:51 - Global step: 5, Loss: 3.096188075840473\n",
      "05/21/2022 10:35:53 - Global step: 6, Loss: 1.9657780975103378\n",
      "05/21/2022 10:35:55 - Global step: 7, Loss: 1.4509596154093742\n",
      "05/21/2022 10:35:57 - Global step: 8, Loss: 1.2778785973787308\n",
      "05/21/2022 10:36:00 - Global step: 9, Loss: 1.0706065967679024\n",
      "05/21/2022 10:36:02 - Global step: 10, Loss: 0.9720774218440056\n",
      "05/21/2022 10:36:04 - Global step: 11, Loss: 0.9952706173062325\n",
      "05/21/2022 10:36:06 - Global step: 12, Loss: 0.9799965769052505\n",
      "05/21/2022 10:36:09 - Global step: 13, Loss: 0.91811902821064\n",
      "05/21/2022 10:36:11 - Global step: 14, Loss: 0.8640283867716789\n",
      "05/21/2022 10:36:13 - Global step: 15, Loss: 0.7425031289458275\n",
      "05/21/2022 10:36:15 - Global step: 16, Loss: 0.8676551356911659\n",
      "05/21/2022 10:36:17 - Global step: 17, Loss: 0.8577861040830612\n",
      "05/21/2022 10:36:20 - Global step: 18, Loss: 0.8020715042948723\n",
      "05/21/2022 10:36:22 - Global step: 19, Loss: 0.6278378404676914\n",
      "05/21/2022 10:36:24 - Global step: 20, Loss: 0.9071264155209064\n",
      "05/21/2022 10:36:26 - Global step: 21, Loss: 0.6072382796555758\n",
      "05/21/2022 10:36:29 - Global step: 22, Loss: 0.7445319071412086\n",
      "05/21/2022 10:36:31 - Global step: 23, Loss: 0.8205208666622639\n",
      "05/21/2022 10:36:33 - Global step: 24, Loss: 0.5803875438869\n",
      "05/21/2022 10:36:35 - Global step: 25, Loss: 0.5757411196827888\n",
      "05/21/2022 10:36:38 - Global step: 26, Loss: 0.5575833264738321\n",
      "05/21/2022 10:36:40 - Global step: 27, Loss: 0.8220310127362609\n",
      "05/21/2022 10:36:42 - Global step: 28, Loss: 0.5267013888806105\n",
      "05/21/2022 10:36:44 - Global step: 29, Loss: 0.6150987194851041\n",
      "05/21/2022 10:36:47 - Global step: 30, Loss: 0.412439638748765\n",
      "05/21/2022 10:36:49 - Global step: 31, Loss: 0.5937488237395883\n",
      "05/21/2022 10:36:51 - Global step: 32, Loss: 0.44218856655061245\n",
      "05/21/2022 10:36:53 - Global step: 33, Loss: 0.9900040905922651\n",
      "05/21/2022 10:36:56 - Global step: 34, Loss: 0.3650125761050731\n",
      "05/21/2022 10:36:58 - Global step: 35, Loss: 0.47821724019013345\n",
      "05/21/2022 10:37:00 - Global step: 36, Loss: 0.10965596899040975\n",
      "05/21/2022 10:37:02 - Global step: 37, Loss: 0.45406438258942217\n",
      "05/21/2022 10:37:05 - Global step: 38, Loss: 0.6633666537236422\n",
      "05/21/2022 10:37:07 - Global step: 39, Loss: 0.4226624039001763\n",
      "05/21/2022 10:37:09 - Global step: 40, Loss: 0.5551248601987027\n",
      "05/21/2022 10:37:11 - Global step: 41, Loss: 0.2566941287368536\n",
      "05/21/2022 10:37:14 - Global step: 42, Loss: 0.33319632802158594\n",
      "05/21/2022 10:37:16 - Global step: 43, Loss: 0.44181410505552776\n",
      "05/21/2022 10:37:18 - Global step: 44, Loss: 0.5508571825921535\n",
      "05/21/2022 10:37:20 - Global step: 45, Loss: 0.3172973543405533\n",
      "05/21/2022 10:37:23 - Global step: 46, Loss: 0.8946272362954915\n",
      "05/21/2022 10:37:25 - Global step: 47, Loss: 0.6847949523944408\n",
      "05/21/2022 10:37:27 - Global step: 48, Loss: 0.271872503508348\n",
      "05/21/2022 10:37:29 - Global step: 49, Loss: 0.8577179206185974\n",
      "05/21/2022 10:37:32 - Global step: 50, Loss: 0.446947876829654\n",
      "05/21/2022 10:37:34 - Global step: 51, Loss: 0.3227106216363609\n",
      "05/21/2022 10:37:36 - Global step: 52, Loss: 0.4339574445039034\n",
      "05/21/2022 10:37:38 - Global step: 53, Loss: 0.622433502227068\n",
      "05/21/2022 10:37:41 - Global step: 54, Loss: 0.4298595250584185\n",
      "05/21/2022 10:37:43 - Global step: 55, Loss: 0.40945393219590187\n",
      "05/21/2022 10:37:45 - Global step: 56, Loss: 0.5435349233448505\n",
      "05/21/2022 10:37:48 - Global step: 57, Loss: 0.34931520372629166\n",
      "05/21/2022 10:37:50 - Global step: 58, Loss: 0.6186632886528969\n",
      "05/21/2022 10:37:52 - Global step: 59, Loss: 0.1610645221080631\n",
      "05/21/2022 10:37:54 - Global step: 60, Loss: 0.5908624990843236\n",
      "05/21/2022 10:37:57 - Global step: 61, Loss: 0.46871951688081026\n",
      "05/21/2022 10:37:59 - Global step: 62, Loss: 0.20135210186708719\n",
      "05/21/2022 10:38:01 - Global step: 63, Loss: 0.30680956318974495\n",
      "05/21/2022 10:38:04 - Global step: 64, Loss: 0.619436543667689\n",
      "05/21/2022 10:38:06 - Global step: 65, Loss: 0.7965912711515557\n",
      "05/21/2022 10:38:08 - Global step: 66, Loss: 0.6657213624566793\n",
      "05/21/2022 10:38:10 - Global step: 67, Loss: 0.2945758500136435\n",
      "05/21/2022 10:38:13 - Global step: 68, Loss: 0.3390389899723232\n",
      "05/21/2022 10:38:15 - Global step: 69, Loss: 0.2944516830611974\n",
      "05/21/2022 10:38:17 - Global step: 70, Loss: 0.7039195594843477\n",
      "05/21/2022 10:38:20 - Global step: 71, Loss: 0.2599052147124894\n",
      "05/21/2022 10:38:22 - Global step: 72, Loss: 0.28168447222560644\n",
      "05/21/2022 10:38:24 - Global step: 73, Loss: 0.58545140363276\n",
      "05/21/2022 10:38:27 - Global step: 74, Loss: 0.20786514785140753\n",
      "05/21/2022 10:38:29 - Global step: 75, Loss: 0.2982039819471538\n",
      "05/21/2022 10:38:31 - Global step: 76, Loss: 0.5583300776779652\n",
      "05/21/2022 10:38:34 - Global step: 77, Loss: 0.23888188996352255\n",
      "05/21/2022 10:38:36 - Global step: 78, Loss: 0.3414302767487243\n",
      "05/21/2022 10:38:38 - Global step: 79, Loss: 0.5018653594888747\n",
      "05/21/2022 10:38:40 - Global step: 80, Loss: 0.2991161923855543\n",
      "05/21/2022 10:38:43 - Global step: 81, Loss: 0.4005896281450987\n",
      "05/21/2022 10:38:45 - Global step: 82, Loss: 0.19403651673928834\n",
      "05/21/2022 10:38:47 - Global step: 83, Loss: 0.16477334348019212\n",
      "05/21/2022 10:38:50 - Global step: 84, Loss: 0.24792213132604957\n",
      "05/21/2022 10:38:52 - Global step: 85, Loss: 0.4312735172279645\n",
      "05/21/2022 10:38:54 - Global step: 86, Loss: 0.4334166744520189\n",
      "05/21/2022 10:38:57 - Global step: 87, Loss: 0.32225450285477564\n",
      "05/21/2022 10:38:59 - Global step: 88, Loss: 0.9654178019263782\n",
      "05/21/2022 10:39:01 - Global step: 89, Loss: 0.7662943612085655\n",
      "05/21/2022 10:39:04 - Global step: 90, Loss: 0.5232121249428019\n",
      "05/21/2022 10:39:06 - Global step: 91, Loss: 0.6602681158110499\n",
      "05/21/2022 10:39:08 - Global step: 92, Loss: 0.4737973427399993\n",
      "05/21/2022 10:39:11 - Global step: 93, Loss: 0.435914984671399\n",
      "05/21/2022 10:39:13 - Global step: 94, Loss: 0.37776922748889774\n",
      "05/21/2022 10:39:15 - Global step: 95, Loss: 0.3143773404881358\n",
      "05/21/2022 10:39:18 - Global step: 96, Loss: 0.4433063408359885\n",
      "05/21/2022 10:39:20 - Global step: 97, Loss: 0.2512766911604558\n",
      "05/21/2022 10:39:22 - Global step: 98, Loss: 0.48082470521330833\n",
      "05/21/2022 10:39:24 - Global step: 99, Loss: 0.6639765733852983\n",
      "05/21/2022 10:39:27 - Global step: 100, Loss: 0.4532226112205535\n",
      "05/21/2022 10:39:29 - Global step: 101, Loss: 0.2998507882002741\n",
      "05/21/2022 10:39:31 - Global step: 102, Loss: 0.43377138674259186\n",
      "05/21/2022 10:39:34 - Global step: 103, Loss: 0.7208826379501261\n",
      "05/21/2022 10:39:36 - Global step: 104, Loss: 0.29649303760379553\n",
      "05/21/2022 10:39:38 - Global step: 105, Loss: 0.3105806963285431\n",
      "05/21/2022 10:39:41 - Global step: 106, Loss: 0.1967301398399286\n",
      "05/21/2022 10:39:43 - Global step: 107, Loss: 0.3071644135634415\n",
      "05/21/2022 10:39:45 - Global step: 108, Loss: 0.448524690233171\n",
      "05/21/2022 10:39:48 - Global step: 109, Loss: 0.299521078937687\n",
      "05/21/2022 10:39:50 - Global step: 110, Loss: 0.5069002173841\n",
      "05/21/2022 10:39:52 - Global step: 111, Loss: 0.444495701813139\n",
      "05/21/2022 10:39:55 - Global step: 112, Loss: 0.2934173360990826\n",
      "05/21/2022 10:39:57 - Global step: 113, Loss: 0.11390082072648511\n",
      "05/21/2022 10:39:59 - Global step: 114, Loss: 0.47375969775021076\n",
      "05/21/2022 10:40:02 - Global step: 115, Loss: 0.44102545734494925\n",
      "05/21/2022 10:40:04 - Global step: 116, Loss: 0.3250974315960775\n",
      "05/21/2022 10:40:06 - Global step: 117, Loss: 0.2658089541009758\n",
      "05/21/2022 10:40:09 - Global step: 118, Loss: 0.514558375813067\n",
      "05/21/2022 10:40:11 - Global step: 119, Loss: 0.6394836591025523\n",
      "05/21/2022 10:40:13 - Global step: 120, Loss: 0.6057247924618423\n",
      "05/21/2022 10:40:16 - Global step: 121, Loss: 0.31844999408349395\n",
      "05/21/2022 10:40:18 - Global step: 122, Loss: 0.456274701282382\n",
      "05/21/2022 10:40:20 - Global step: 123, Loss: 0.3072216084692627\n",
      "05/21/2022 10:40:22 - Global step: 124, Loss: 0.14430784943397157\n",
      "05/21/2022 10:40:25 - Global step: 125, Loss: 0.4066387661732733\n",
      "05/21/2022 10:40:27 - Global step: 126, Loss: 0.25329242437146604\n",
      "05/21/2022 10:40:29 - Global step: 127, Loss: 0.6005895132257137\n",
      "05/21/2022 10:40:32 - Global step: 128, Loss: 0.29595735436305404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/21/2022 10:40:34 - Global step: 129, Loss: 0.4234402262227377\n",
      "05/21/2022 10:40:36 - Global step: 130, Loss: 0.21183882901095785\n",
      "05/21/2022 10:40:39 - Global step: 131, Loss: 0.3094257520278916\n",
      "05/21/2022 10:40:41 - Global step: 132, Loss: 0.40566449971356633\n",
      "05/21/2022 10:40:43 - Global step: 133, Loss: 0.18700280884513631\n",
      "05/21/2022 10:40:46 - Global step: 134, Loss: 0.29573563238955103\n",
      "05/21/2022 10:40:48 - Global step: 135, Loss: 0.1785631966777146\n",
      "05/21/2022 10:40:50 - Global step: 136, Loss: 0.33984838642936666\n",
      "05/21/2022 10:40:53 - Global step: 137, Loss: 0.13377561868674093\n",
      "05/21/2022 10:40:55 - Global step: 138, Loss: 0.3025989352436227\n",
      "05/21/2022 10:40:57 - Global step: 139, Loss: 0.3410001657612156\n",
      "05/21/2022 10:41:00 - Global step: 140, Loss: 0.12299411039816732\n",
      "05/21/2022 10:41:02 - Global step: 141, Loss: 0.4026500241016038\n",
      "05/21/2022 10:41:04 - Global step: 142, Loss: 0.19943159352988005\n",
      "05/21/2022 10:41:07 - Global step: 143, Loss: 0.056433035773807205\n",
      "05/21/2022 10:41:09 - Global step: 144, Loss: 0.3294862206385005\n",
      "05/21/2022 10:41:11 - Global step: 145, Loss: 0.28467327854014\n",
      "05/21/2022 10:41:14 - Global step: 146, Loss: 0.2081729194469517\n",
      "05/21/2022 10:41:16 - Global step: 147, Loss: 0.7020193568896502\n",
      "05/21/2022 10:41:18 - Global step: 148, Loss: 0.35306401271373034\n",
      "05/21/2022 10:41:21 - Global step: 149, Loss: 0.3052060285017433\n",
      "05/21/2022 10:41:23 - Global step: 150, Loss: 0.18310700388246914\n",
      "05/21/2022 10:41:25 - Global step: 151, Loss: 0.1291274723052993\n",
      "05/21/2022 10:41:27 - Global step: 152, Loss: 0.1461854252847843\n",
      "05/21/2022 10:41:30 - Global step: 153, Loss: 0.5147846128093079\n",
      "05/21/2022 10:41:32 - Global step: 154, Loss: 0.3669713643321302\n",
      "05/21/2022 10:41:34 - Global step: 155, Loss: 0.30366241931915283\n",
      "05/21/2022 10:41:37 - Global step: 156, Loss: 0.2794602659996599\n",
      "05/21/2022 10:41:39 - Global step: 157, Loss: 0.6211113499011844\n",
      "05/21/2022 10:41:41 - Global step: 158, Loss: 0.19475693756248802\n",
      "05/21/2022 10:41:44 - Global step: 159, Loss: 0.18828338042840187\n",
      "05/21/2022 10:41:46 - Global step: 160, Loss: 0.24623873154632747\n",
      "05/21/2022 10:41:48 - Global step: 161, Loss: 0.434963992331177\n",
      "05/21/2022 10:41:51 - Global step: 162, Loss: 0.6440355686936527\n",
      "05/21/2022 10:41:53 - Global step: 163, Loss: 0.2557373571326025\n",
      "05/21/2022 10:41:55 - Global step: 164, Loss: 0.2532191211357713\n",
      "05/21/2022 10:41:58 - Global step: 165, Loss: 0.2275476016511675\n",
      "05/21/2022 10:42:00 - Global step: 166, Loss: 0.09315827675163746\n",
      "05/21/2022 10:42:02 - Global step: 167, Loss: 0.6777853392413817\n",
      "05/21/2022 10:42:05 - Global step: 168, Loss: 0.18322965572588146\n",
      "05/21/2022 10:42:07 - Global step: 169, Loss: 0.43065481369558256\n",
      "05/21/2022 10:42:09 - Global step: 170, Loss: 0.6229569774004631\n",
      "05/21/2022 10:42:11 - Global step: 171, Loss: 0.2768485685810447\n",
      "05/21/2022 10:42:14 - Global step: 172, Loss: 0.3067320319823921\n",
      "05/21/2022 10:42:16 - Global step: 173, Loss: 0.44144682912155986\n",
      "05/21/2022 10:42:18 - Global step: 174, Loss: 0.4784058662626194\n",
      "05/21/2022 10:42:21 - Global step: 175, Loss: 0.45765215577557683\n",
      "05/21/2022 10:42:23 - Global step: 176, Loss: 0.2429462990257889\n",
      "05/21/2022 10:42:25 - Global step: 177, Loss: 0.19781780615448952\n",
      "05/21/2022 10:42:28 - Global step: 178, Loss: 0.21540937904501334\n",
      "05/21/2022 10:42:30 - Global step: 179, Loss: 0.2247894188039936\n",
      "05/21/2022 10:42:32 - Global step: 180, Loss: 0.47347458414151333\n",
      "05/21/2022 10:42:35 - Global step: 181, Loss: 0.18557216072804295\n",
      "05/21/2022 10:42:37 - Global step: 182, Loss: 0.5664946767719812\n",
      "05/21/2022 10:42:39 - Global step: 183, Loss: 0.42268536175834015\n",
      "05/21/2022 10:42:42 - Global step: 184, Loss: 0.23669230955420062\n",
      "05/21/2022 10:42:44 - Global step: 185, Loss: 0.7529851582366973\n",
      "05/21/2022 10:42:46 - Global step: 186, Loss: 0.3077377774316119\n",
      "05/21/2022 10:42:49 - Global step: 187, Loss: 0.36396316811442375\n",
      "05/21/2022 10:42:51 - Global step: 188, Loss: 0.12051775664440356\n",
      "05/21/2022 10:42:53 - Global step: 189, Loss: 0.13024762261193246\n",
      "05/21/2022 10:42:56 - Global step: 190, Loss: 0.07613426115131006\n",
      "05/21/2022 10:42:58 - Global step: 191, Loss: 0.3884543525055051\n",
      "05/21/2022 10:43:00 - Global step: 192, Loss: 0.2806775766730425\n",
      "05/21/2022 10:43:03 - Global step: 193, Loss: 0.030045356164919212\n",
      "05/21/2022 10:43:05 - Global step: 194, Loss: 0.19651594437891617\n",
      "05/21/2022 10:43:07 - Global step: 195, Loss: 0.28043183288536966\n",
      "05/21/2022 10:43:09 - Global step: 196, Loss: 0.14549873518990353\n",
      "05/21/2022 10:43:12 - Global step: 197, Loss: 0.09776231870637275\n",
      "05/21/2022 10:43:14 - Global step: 198, Loss: 0.18034416271257214\n",
      "05/21/2022 10:43:16 - Global step: 199, Loss: 0.22615338733885437\n",
      "05/21/2022 10:43:19 - Global step: 200, Loss: 0.14433614873087208\n",
      "05/21/2022 10:43:21 - Global step: 201, Loss: 0.25996756489621475\n",
      "05/21/2022 10:43:23 - Global step: 202, Loss: 0.04022011526831193\n",
      "05/21/2022 10:43:26 - Global step: 203, Loss: 0.159596006222273\n",
      "05/21/2022 10:43:28 - Global step: 204, Loss: 0.18146505993445317\n",
      "05/21/2022 10:43:30 - Global step: 205, Loss: 0.22859838809017674\n",
      "05/21/2022 10:43:33 - Global step: 206, Loss: 0.2854236949933693\n",
      "05/21/2022 10:43:35 - Global step: 207, Loss: 0.323920595634263\n",
      "05/21/2022 10:43:37 - Global step: 208, Loss: 0.05307381046804949\n",
      "05/21/2022 10:43:40 - Global step: 209, Loss: 0.13455215313115332\n",
      "05/21/2022 10:43:42 - Global step: 210, Loss: 0.19659398245812554\n",
      "05/21/2022 10:43:44 - Global step: 211, Loss: 0.026598700555041432\n",
      "05/21/2022 10:43:47 - Global step: 212, Loss: 0.16777654287398036\n",
      "05/21/2022 10:43:49 - Global step: 213, Loss: 0.458466926793335\n",
      "05/21/2022 10:43:51 - Global step: 214, Loss: 0.09901112108855159\n",
      "05/21/2022 10:43:54 - Global step: 215, Loss: 0.4171970534434877\n",
      "05/21/2022 10:43:56 - Global step: 216, Loss: 0.10311840156100516\n",
      "05/21/2022 10:43:58 - Global step: 217, Loss: 0.43206581979757175\n",
      "05/21/2022 10:44:01 - Global step: 218, Loss: 0.3421694836433744\n",
      "05/21/2022 10:44:03 - Global step: 219, Loss: 0.3537862591783778\n",
      "05/21/2022 10:44:05 - Global step: 220, Loss: 0.30456633333233185\n",
      "05/21/2022 10:44:07 - Global step: 221, Loss: 0.3269479510054225\n",
      "05/21/2022 10:44:10 - Global step: 222, Loss: 0.29588566080383316\n",
      "05/21/2022 10:44:12 - Global step: 223, Loss: 0.28890103785306565\n",
      "05/21/2022 10:44:14 - Global step: 224, Loss: 0.21085509969270788\n",
      "05/21/2022 10:44:17 - Global step: 225, Loss: 0.20476868798141368\n",
      "05/21/2022 10:44:19 - Global step: 226, Loss: 0.426818033476593\n",
      "05/21/2022 10:44:21 - Global step: 227, Loss: 0.22135172204798437\n",
      "05/21/2022 10:44:24 - Global step: 228, Loss: 0.12619217671453953\n",
      "05/21/2022 10:44:26 - Global step: 229, Loss: 0.5363400461501442\n",
      "05/21/2022 10:44:28 - Global step: 230, Loss: 0.32180594734381884\n",
      "05/21/2022 10:44:31 - Global step: 231, Loss: 0.4725236285594292\n",
      "05/21/2022 10:44:33 - Global step: 232, Loss: 0.44544644736743066\n",
      "05/21/2022 10:44:35 - Global step: 233, Loss: 0.17696247171261348\n",
      "05/21/2022 10:44:38 - Global step: 234, Loss: 0.18913387924840208\n",
      "05/21/2022 10:44:40 - Global step: 235, Loss: 0.4591669369256124\n",
      "05/21/2022 10:44:42 - Global step: 236, Loss: 0.3621418694820022\n",
      "05/21/2022 10:44:45 - Global step: 237, Loss: 0.140370714601886\n",
      "05/21/2022 10:44:47 - Global step: 238, Loss: 0.15619316254742444\n",
      "05/21/2022 10:44:49 - Global step: 239, Loss: 0.34950763077358715\n",
      "05/21/2022 10:44:52 - Global step: 240, Loss: 0.11670260118262377\n",
      "05/21/2022 10:44:54 - Global step: 241, Loss: 0.05896028802089859\n",
      "05/21/2022 10:44:56 - Global step: 242, Loss: 0.27320540869550314\n",
      "05/21/2022 10:44:59 - Global step: 243, Loss: 0.11484150812520966\n",
      "05/21/2022 10:45:01 - Global step: 244, Loss: 0.31721755391481565\n",
      "05/21/2022 10:45:03 - Global step: 245, Loss: 0.14803445228608325\n",
      "05/21/2022 10:45:06 - Global step: 246, Loss: 0.2819631062448025\n",
      "05/21/2022 10:45:08 - Global step: 247, Loss: 0.058115105581237\n",
      "05/21/2022 10:45:10 - Global step: 248, Loss: 0.05283217752003111\n",
      "05/21/2022 10:45:13 - Global step: 249, Loss: 0.09679179619706701\n",
      "05/21/2022 10:45:15 - Global step: 250, Loss: 0.2305282719898969\n",
      "05/21/2022 10:45:17 - Global step: 251, Loss: 0.17231203258779715\n",
      "05/21/2022 10:45:20 - Global step: 252, Loss: 0.24876221676822752\n",
      "05/21/2022 10:45:22 - Global step: 253, Loss: 0.07428928039735183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/21/2022 10:45:24 - Global step: 254, Loss: 0.3954338371368067\n",
      "05/21/2022 10:45:26 - Global step: 255, Loss: 0.15142365894280374\n",
      "05/21/2022 10:45:29 - Global step: 256, Loss: 0.32004895668069366\n",
      "05/21/2022 10:45:31 - Global step: 257, Loss: 0.10691959245014004\n",
      "05/21/2022 10:45:33 - Global step: 258, Loss: 0.30916666077973787\n",
      "05/21/2022 10:45:36 - Global step: 259, Loss: 0.28138221471635916\n",
      "05/21/2022 10:45:38 - Global step: 260, Loss: 0.23192372704397712\n",
      "05/21/2022 10:45:40 - Global step: 261, Loss: 0.2158539762494911\n",
      "05/21/2022 10:45:43 - Global step: 262, Loss: 0.19294150618225103\n",
      "05/21/2022 10:45:45 - Global step: 263, Loss: 0.10684889867206948\n",
      "05/21/2022 10:45:47 - Global step: 264, Loss: 0.023207703528896673\n",
      "05/21/2022 10:45:50 - Global step: 265, Loss: 0.050495614397732425\n",
      "05/21/2022 10:45:52 - Global step: 266, Loss: 0.3051826707669534\n",
      "05/21/2022 10:45:54 - Global step: 267, Loss: 0.16322556163777335\n",
      "05/21/2022 10:45:57 - Global step: 268, Loss: 0.20387095065234462\n",
      "05/21/2022 10:45:59 - Global step: 269, Loss: 0.47077698141401925\n",
      "05/21/2022 10:46:01 - Global step: 270, Loss: 0.46197067166758643\n",
      "05/21/2022 10:46:04 - Global step: 271, Loss: 0.22381315021630144\n",
      "05/21/2022 10:46:06 - Global step: 272, Loss: 0.23161935759708285\n",
      "05/21/2022 10:46:08 - Global step: 273, Loss: 1.3405417427420616\n",
      "05/21/2022 10:46:11 - Global step: 274, Loss: 0.41005910839885473\n",
      "05/21/2022 10:46:13 - Global step: 275, Loss: 0.09376592410262674\n",
      "05/21/2022 10:46:15 - Global step: 276, Loss: 0.19223738508298993\n",
      "05/21/2022 10:46:18 - Global step: 277, Loss: 0.16695371962850913\n",
      "05/21/2022 10:46:20 - Global step: 278, Loss: 0.2991626029834151\n",
      "05/21/2022 10:46:22 - Global step: 279, Loss: 0.25520316109759733\n",
      "05/21/2022 10:46:24 - Global step: 280, Loss: 0.18734694772865623\n",
      "05/21/2022 10:46:27 - Global step: 281, Loss: 0.36272927559912205\n",
      "05/21/2022 10:46:29 - Global step: 282, Loss: 0.2530726946424693\n",
      "05/21/2022 10:46:31 - Global step: 283, Loss: 0.1657367948209867\n",
      "05/21/2022 10:46:34 - Global step: 284, Loss: 0.13273943623062223\n",
      "05/21/2022 10:46:36 - Global step: 285, Loss: 0.31147117377258837\n",
      "05/21/2022 10:46:38 - Global step: 286, Loss: 0.2556726045149844\n",
      "05/21/2022 10:46:41 - Global step: 287, Loss: 0.17521983198821545\n",
      "05/21/2022 10:46:43 - Global step: 288, Loss: 0.23167372128227726\n",
      "05/21/2022 10:46:45 - Global step: 289, Loss: 0.40631016649422236\n",
      "05/21/2022 10:46:48 - Global step: 290, Loss: 0.19659289822448045\n",
      "05/21/2022 10:46:50 - Global step: 291, Loss: 0.3152294437168166\n",
      "05/21/2022 10:46:52 - Global step: 292, Loss: 0.4373238639673218\n",
      "05/21/2022 10:46:55 - Global step: 293, Loss: 0.1238784426386701\n",
      "05/21/2022 10:46:57 - Global step: 294, Loss: 0.15601779223652557\n",
      "05/21/2022 10:46:59 - Global step: 295, Loss: 0.16194037394598126\n",
      "05/21/2022 10:47:02 - Global step: 296, Loss: 0.4126756992773153\n",
      "05/21/2022 10:47:04 - Global step: 297, Loss: 0.38017834012862295\n",
      "05/21/2022 10:47:06 - Global step: 298, Loss: 0.1213573986897245\n",
      "05/21/2022 10:47:09 - Global step: 299, Loss: 0.20790241393842734\n",
      "05/21/2022 10:47:11 - Global step: 300, Loss: 0.09551635538809933\n",
      "05/21/2022 10:47:13 - Global step: 301, Loss: 0.14229936676565558\n",
      "05/21/2022 10:47:16 - Global step: 302, Loss: 0.20673013840132626\n",
      "05/21/2022 10:47:18 - Global step: 303, Loss: 0.33490226630237885\n",
      "05/21/2022 10:47:20 - Global step: 304, Loss: 0.10877040052582743\n",
      "05/21/2022 10:47:23 - Global step: 305, Loss: 0.10198409069562331\n",
      "05/21/2022 10:47:25 - Global step: 306, Loss: 0.22983781049697427\n",
      "05/21/2022 10:47:27 - Global step: 307, Loss: 0.1604574974408024\n",
      "05/21/2022 10:47:30 - Global step: 308, Loss: 0.2598250472074142\n",
      "05/21/2022 10:47:32 - Global step: 309, Loss: 0.31951097096316516\n",
      "05/21/2022 10:47:34 - Global step: 310, Loss: 0.0732131681033934\n",
      "05/21/2022 10:47:37 - Global step: 311, Loss: 0.032947956744465046\n",
      "05/21/2022 10:47:39 - Global step: 312, Loss: 0.349713529649307\n",
      "05/21/2022 10:47:41 - Global step: 313, Loss: 0.5860969708264747\n",
      "05/21/2022 10:47:44 - Global step: 314, Loss: 0.43205683860287536\n",
      "05/21/2022 10:47:46 - Global step: 315, Loss: 0.15090969757875428\n",
      "05/21/2022 10:47:48 - Global step: 316, Loss: 0.1492299936071504\n",
      "05/21/2022 10:47:51 - Global step: 317, Loss: 0.1419768305204343\n",
      "05/21/2022 10:47:53 - Global step: 318, Loss: 0.10299207438947633\n",
      "05/21/2022 10:47:55 - Global step: 319, Loss: 0.21434510969993426\n",
      "05/21/2022 10:47:58 - Global step: 320, Loss: 0.10788770967701566\n",
      "05/21/2022 10:48:00 - Global step: 321, Loss: 0.35091435228423506\n",
      "05/21/2022 10:48:02 - Global step: 322, Loss: 0.17615432943603082\n",
      "05/21/2022 10:48:05 - Global step: 323, Loss: 0.12465690297540277\n",
      "05/21/2022 10:48:07 - Global step: 324, Loss: 0.1949233514314983\n",
      "05/21/2022 10:48:09 - Global step: 325, Loss: 0.12616238326154416\n",
      "05/21/2022 10:48:12 - Global step: 326, Loss: 0.04158107710827608\n",
      "05/21/2022 10:48:14 - Global step: 327, Loss: 0.18264903021190548\n",
      "05/21/2022 10:48:16 - Global step: 328, Loss: 0.07365444782931263\n",
      "05/21/2022 10:48:19 - Global step: 329, Loss: 0.19612595190119464\n",
      "05/21/2022 10:48:21 - Global step: 330, Loss: 0.1679528839267732\n",
      "05/21/2022 10:48:23 - Global step: 331, Loss: 0.2724253724964001\n",
      "05/21/2022 10:48:26 - Global step: 332, Loss: 0.0593689969659863\n",
      "05/21/2022 10:48:28 - Global step: 333, Loss: 0.20206888188113226\n",
      "05/21/2022 10:48:30 - Global step: 334, Loss: 0.6200409105076687\n",
      "05/21/2022 10:48:33 - Global step: 335, Loss: 0.24746512691490352\n",
      "05/21/2022 10:48:35 - Global step: 336, Loss: 0.33420248341280967\n",
      "05/21/2022 10:48:37 - Global step: 337, Loss: 0.11390520884015132\n",
      "05/21/2022 10:48:40 - Global step: 338, Loss: 0.20260076189879328\n",
      "05/21/2022 10:48:42 - Global step: 339, Loss: 0.051525536604458466\n",
      "05/21/2022 10:48:44 - Global step: 340, Loss: 0.4750656176765915\n",
      "05/21/2022 10:48:47 - Global step: 341, Loss: 0.1408583476295462\n",
      "05/21/2022 10:48:49 - Global step: 342, Loss: 0.11187977832742035\n",
      "05/21/2022 10:48:51 - Global step: 343, Loss: 0.1273595515958732\n",
      "05/21/2022 10:48:54 - Global step: 344, Loss: 0.1424498077831231\n",
      "05/21/2022 10:48:56 - Global step: 345, Loss: 0.3031549656370771\n",
      "05/21/2022 10:48:58 - Global step: 346, Loss: 0.45655644324142486\n",
      "05/21/2022 10:49:01 - Global step: 347, Loss: 0.4205226333651808\n",
      "05/21/2022 10:49:03 - Global step: 348, Loss: 0.18074664426967502\n",
      "05/21/2022 10:49:05 - Global step: 349, Loss: 0.28725451952777803\n",
      "05/21/2022 10:49:08 - Global step: 350, Loss: 0.2578374997174251\n",
      "05/21/2022 10:49:10 - Global step: 351, Loss: 0.24335726536810398\n",
      "05/21/2022 10:49:12 - Global step: 352, Loss: 0.08205984216692741\n",
      "05/21/2022 10:49:15 - Global step: 353, Loss: 0.13742842378269415\n",
      "05/21/2022 10:49:17 - Global step: 354, Loss: 0.46892802650108933\n",
      "05/21/2022 10:49:19 - Global step: 355, Loss: 0.3295573501090985\n",
      "05/21/2022 10:49:22 - Global step: 356, Loss: 0.2667060513049364\n",
      "05/21/2022 10:49:24 - Global step: 357, Loss: 0.30899825842061546\n",
      "05/21/2022 10:49:26 - Global step: 358, Loss: 0.4253151679877192\n",
      "05/21/2022 10:49:29 - Global step: 359, Loss: 0.31783853145316243\n",
      "05/21/2022 10:49:31 - Global step: 360, Loss: 0.2110198158188723\n",
      "05/21/2022 10:49:33 - Global step: 361, Loss: 0.17191977752372622\n",
      "05/21/2022 10:49:36 - Global step: 362, Loss: 0.075651649676729\n",
      "05/21/2022 10:49:38 - Global step: 363, Loss: 0.06022457033395767\n",
      "05/21/2022 10:49:40 - Global step: 364, Loss: 0.18114644290471915\n",
      "05/21/2022 10:49:43 - Global step: 365, Loss: 0.17878642305731773\n",
      "05/21/2022 10:49:45 - Global step: 366, Loss: 0.11861684959148988\n",
      "05/21/2022 10:49:47 - Global step: 367, Loss: 0.4652821598574519\n",
      "05/21/2022 10:49:50 - Global step: 368, Loss: 0.4826212108018808\n",
      "05/21/2022 10:49:52 - Global step: 369, Loss: 0.3002668875233212\n",
      "05/21/2022 10:49:54 - Global step: 370, Loss: 0.32286635373020545\n",
      "05/21/2022 10:49:57 - Global step: 371, Loss: 0.14557462779339403\n",
      "05/21/2022 10:49:59 - Global step: 372, Loss: 0.15913237497443333\n",
      "05/21/2022 10:50:01 - Global step: 373, Loss: 0.09300587628240464\n",
      "05/21/2022 10:50:04 - Global step: 374, Loss: 0.05957318866785499\n",
      "05/21/2022 10:50:06 - Global step: 375, Loss: 0.14468899040002725\n",
      "05/21/2022 10:50:08 - Global step: 376, Loss: 0.2964594691657112\n",
      "05/21/2022 10:50:11 - Global step: 377, Loss: 0.4743429271884452\n",
      "05/21/2022 10:50:13 - Global step: 378, Loss: 0.17154556237846919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/21/2022 10:50:15 - Global step: 379, Loss: 0.1421679378945555\n",
      "05/21/2022 10:50:18 - Global step: 380, Loss: 0.26544646406364336\n",
      "05/21/2022 10:50:20 - Global step: 381, Loss: 0.25363868060230743\n",
      "05/21/2022 10:50:22 - Global step: 382, Loss: 0.06412816949341504\n",
      "05/21/2022 10:50:25 - Global step: 383, Loss: 0.02714809204917401\n",
      "05/21/2022 10:50:27 - Global step: 384, Loss: 0.10148371961622615\n",
      "05/21/2022 10:50:30 - Global step: 385, Loss: 0.05646180326675676\n",
      "05/21/2022 10:50:32 - Global step: 386, Loss: 0.013219055470244712\n",
      "05/21/2022 10:50:34 - Global step: 387, Loss: 0.18574646252893956\n",
      "05/21/2022 10:50:37 - Global step: 388, Loss: 0.19770557625997753\n",
      "05/21/2022 10:50:39 - Global step: 389, Loss: 0.04448755308953878\n",
      "05/21/2022 10:50:41 - Global step: 390, Loss: 0.0357583058344062\n",
      "05/21/2022 10:50:44 - Global step: 391, Loss: 0.051146463939232945\n",
      "05/21/2022 10:50:46 - Global step: 392, Loss: 0.3725028595661115\n",
      "05/21/2022 10:50:48 - Global step: 393, Loss: 0.11559996784563964\n",
      "05/21/2022 10:50:51 - Global step: 394, Loss: 0.07259237753896741\n",
      "05/21/2022 10:50:53 - Global step: 395, Loss: 0.35902233726483246\n",
      "05/21/2022 10:50:55 - Global step: 396, Loss: 0.06072612677019151\n",
      "05/21/2022 10:50:58 - Global step: 397, Loss: 0.1021151734948944\n",
      "05/21/2022 10:51:00 - Global step: 398, Loss: 0.18840781040489674\n",
      "05/21/2022 10:51:02 - Global step: 399, Loss: 0.06380494387940416\n",
      "05/21/2022 10:51:05 - Global step: 400, Loss: 0.30133907990330044\n",
      "05/21/2022 10:51:07 - Global step: 401, Loss: 0.09628264564844358\n",
      "05/21/2022 10:51:09 - Global step: 402, Loss: 0.03423280991273714\n",
      "05/21/2022 10:51:12 - Global step: 403, Loss: 0.18494177143520574\n",
      "05/21/2022 10:51:14 - Global step: 404, Loss: 0.43286076984782085\n",
      "05/21/2022 10:51:16 - Global step: 405, Loss: 0.2821365899526427\n",
      "05/21/2022 10:51:19 - Global step: 406, Loss: 0.6956418676880674\n",
      "05/21/2022 10:51:21 - Global step: 407, Loss: 0.4481954205875809\n",
      "05/21/2022 10:51:23 - Global step: 408, Loss: 0.026678224645365844\n",
      "05/21/2022 10:51:26 - Global step: 409, Loss: 0.15322359980200417\n",
      "05/21/2022 10:51:28 - Global step: 410, Loss: 0.1231431471533142\n",
      "05/21/2022 10:51:30 - Global step: 411, Loss: 0.5886679392424412\n",
      "05/21/2022 10:51:33 - Global step: 412, Loss: 0.3154938392362965\n",
      "05/21/2022 10:51:35 - Global step: 413, Loss: 0.17869809427065775\n",
      "05/21/2022 10:51:37 - Global step: 414, Loss: 0.19364821934505017\n",
      "05/21/2022 10:51:40 - Global step: 415, Loss: 0.3533463367493823\n",
      "05/21/2022 10:51:42 - Global step: 416, Loss: 0.1682375777454581\n",
      "05/21/2022 10:51:44 - Global step: 417, Loss: 0.28005742630921304\n",
      "05/21/2022 10:51:47 - Global step: 418, Loss: 0.6451298212632537\n",
      "05/21/2022 10:51:49 - Global step: 419, Loss: 0.12275665435299743\n",
      "05/21/2022 10:51:51 - Global step: 420, Loss: 0.06121696237823926\n",
      "05/21/2022 10:51:54 - Global step: 421, Loss: 0.4487475904170424\n",
      "05/21/2022 10:51:56 - Global step: 422, Loss: 0.5690934857120737\n",
      "05/21/2022 10:51:58 - Global step: 423, Loss: 0.33747204071551096\n",
      "05/21/2022 10:52:01 - Global step: 424, Loss: 0.21261768045951612\n",
      "05/21/2022 10:52:03 - Global step: 425, Loss: 0.3504528303164989\n",
      "05/21/2022 10:52:05 - Global step: 426, Loss: 0.3407703919801861\n",
      "05/21/2022 10:52:08 - Global step: 427, Loss: 0.3216022941051051\n",
      "05/21/2022 10:52:10 - Global step: 428, Loss: 0.4632413105573505\n",
      "05/21/2022 10:52:12 - Global step: 429, Loss: 0.18340997130144387\n",
      "05/21/2022 10:52:15 - Global step: 430, Loss: 0.23148196609690785\n",
      "05/21/2022 10:52:17 - Global step: 431, Loss: 0.04514526453567669\n",
      "05/21/2022 10:52:19 - Global step: 432, Loss: 0.2814420862705447\n",
      "05/21/2022 10:52:22 - Global step: 433, Loss: 0.13669368624687195\n",
      "05/21/2022 10:52:24 - Global step: 434, Loss: 0.2313922067405656\n",
      "05/21/2022 10:52:26 - Global step: 435, Loss: 0.16954931989312172\n",
      "05/21/2022 10:52:29 - Global step: 436, Loss: 0.11293691192986444\n",
      "05/21/2022 10:52:31 - Global step: 437, Loss: 0.2922629176755436\n",
      "05/21/2022 10:52:33 - Global step: 438, Loss: 0.07322312680480536\n",
      "05/21/2022 10:52:36 - Global step: 439, Loss: 0.0445298834820278\n",
      "05/21/2022 10:52:38 - Global step: 440, Loss: 0.20063769281841815\n",
      "05/21/2022 10:52:40 - Global step: 441, Loss: 0.0844522984843934\n",
      "05/21/2022 10:52:43 - Global step: 442, Loss: 0.16718296555336565\n",
      "05/21/2022 10:52:45 - Global step: 443, Loss: 0.33256022315254086\n",
      "05/21/2022 10:52:47 - Global step: 444, Loss: 0.47906140130362473\n",
      "05/21/2022 10:52:50 - Global step: 445, Loss: 0.5786322869680589\n",
      "05/21/2022 10:52:52 - Global step: 446, Loss: 0.09087031723174732\n",
      "05/21/2022 10:52:54 - Global step: 447, Loss: 0.208296442811843\n",
      "05/21/2022 10:52:57 - Global step: 448, Loss: 0.1553946421481669\n",
      "05/21/2022 10:52:59 - Global step: 449, Loss: 0.1024030574481003\n",
      "05/21/2022 10:53:01 - Global step: 450, Loss: 0.041170201962813735\n",
      "05/21/2022 10:53:04 - Global step: 451, Loss: 0.16156890141428448\n",
      "05/21/2022 10:53:06 - Global step: 452, Loss: 0.11847046960610896\n",
      "05/21/2022 10:53:08 - Global step: 453, Loss: 0.19938094455210376\n",
      "05/21/2022 10:53:11 - Global step: 454, Loss: 0.030103096170932986\n",
      "05/21/2022 10:53:13 - Global step: 455, Loss: 0.1323649791884236\n",
      "05/21/2022 10:53:15 - Global step: 456, Loss: 0.13580757701129187\n",
      "05/21/2022 10:53:18 - Global step: 457, Loss: 0.03386507838149555\n",
      "05/21/2022 10:53:20 - Global step: 458, Loss: 0.10151706423494034\n",
      "05/21/2022 10:53:22 - Global step: 459, Loss: 0.08054365745556424\n",
      "05/21/2022 10:53:25 - Global step: 460, Loss: 0.10047238565312\n",
      "05/21/2022 10:53:27 - Global step: 461, Loss: 0.16629131510853767\n",
      "05/21/2022 10:53:29 - Global step: 462, Loss: 0.409060499703628\n",
      "05/21/2022 10:53:32 - Global step: 463, Loss: 0.4514757721917704\n",
      "05/21/2022 10:53:34 - Global step: 464, Loss: 0.025384758300788235\n",
      "05/21/2022 10:53:36 - Global step: 465, Loss: 0.1690054226492066\n",
      "05/21/2022 10:53:39 - Global step: 466, Loss: 0.28182637170903035\n",
      "05/21/2022 10:53:41 - Global step: 467, Loss: 0.028012232498440426\n",
      "05/21/2022 10:53:43 - Global step: 468, Loss: 0.07957347345654853\n",
      "05/21/2022 10:53:46 - Global step: 469, Loss: 0.3083420124821714\n",
      "05/21/2022 10:53:48 - Global step: 470, Loss: 0.4385016988089774\n",
      "05/21/2022 10:53:50 - Global step: 471, Loss: 0.21458863731095335\n",
      "05/21/2022 10:53:53 - Global step: 472, Loss: 0.19317774163209833\n",
      "05/21/2022 10:53:55 - Global step: 473, Loss: 0.2516563817007409\n",
      "05/21/2022 10:53:57 - Global step: 474, Loss: 0.29234576437738724\n",
      "05/21/2022 10:54:00 - Global step: 475, Loss: 0.18079499840678181\n",
      "05/21/2022 10:54:02 - Global step: 476, Loss: 0.21697845525341108\n",
      "05/21/2022 10:54:04 - Global step: 477, Loss: 0.1769595756486524\n",
      "05/21/2022 10:54:07 - Global step: 478, Loss: 0.14841272293779184\n",
      "05/21/2022 10:54:09 - Global step: 479, Loss: 0.07892378135875333\n",
      "05/21/2022 10:54:11 - Global step: 480, Loss: 0.7237151792905934\n",
      "05/21/2022 10:54:14 - Global step: 481, Loss: 0.3444638567743823\n",
      "05/21/2022 10:54:16 - Global step: 482, Loss: 0.1367598266369896\n",
      "05/21/2022 10:54:18 - Global step: 483, Loss: 0.08935629960615188\n",
      "05/21/2022 10:54:21 - Global step: 484, Loss: 0.09203778556548059\n",
      "05/21/2022 10:54:23 - Global step: 485, Loss: 0.09851822606287897\n",
      "05/21/2022 10:54:25 - Global step: 486, Loss: 0.0897713273880072\n",
      "05/21/2022 10:54:28 - Global step: 487, Loss: 0.08885349008778576\n",
      "05/21/2022 10:54:30 - Global step: 488, Loss: 0.09990352414024528\n",
      "05/21/2022 10:54:32 - Global step: 489, Loss: 0.12517678950098343\n",
      "05/21/2022 10:54:35 - Global step: 490, Loss: 0.24182292570185382\n",
      "05/21/2022 10:54:37 - Global step: 491, Loss: 0.11242451997532044\n",
      "05/21/2022 10:54:39 - Global step: 492, Loss: 0.09519865212860168\n",
      "05/21/2022 10:54:42 - Global step: 493, Loss: 0.11860579159110785\n",
      "05/21/2022 10:54:44 - Global step: 494, Loss: 0.07971457872190513\n",
      "05/21/2022 10:54:46 - Global step: 495, Loss: 0.05227053927956149\n",
      "05/21/2022 10:54:49 - Global step: 496, Loss: 0.04154088704626702\n",
      "05/21/2022 10:54:51 - Global step: 497, Loss: 0.04278700639360977\n",
      "05/21/2022 10:54:53 - Global step: 498, Loss: 0.14370750257512555\n",
      "05/21/2022 10:54:56 - Global step: 499, Loss: 0.031086672246601665\n",
      "05/21/2022 10:54:58 - Global step: 500, Loss: 0.7719659071099159\n",
      "05/21/2022 10:55:00 - Global step: 501, Loss: 0.022499838935800653\n",
      "05/21/2022 10:55:02 - Global step: 502, Loss: 0.052355825009726686\n",
      "05/21/2022 10:55:05 - Global step: 503, Loss: 0.03593080650944103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/21/2022 10:55:07 - Global step: 504, Loss: 0.36899678907866473\n",
      "05/21/2022 10:55:09 - Global step: 505, Loss: 0.43439325816689234\n",
      "05/21/2022 10:55:12 - Global step: 506, Loss: 0.13846958874273696\n",
      "05/21/2022 10:55:14 - Global step: 507, Loss: 0.5269770858712377\n",
      "05/21/2022 10:55:16 - Global step: 508, Loss: 0.3511665328296658\n",
      "05/21/2022 10:55:19 - Global step: 509, Loss: 0.2712608630245086\n",
      "05/21/2022 10:55:21 - Global step: 510, Loss: 0.022562370020693834\n",
      "05/21/2022 10:55:23 - Global step: 511, Loss: 0.030909006445654086\n",
      "05/21/2022 10:55:26 - Global step: 512, Loss: 0.023597361152496887\n",
      "05/21/2022 10:55:28 - Global step: 513, Loss: 0.08089542265679484\n",
      "05/21/2022 10:55:30 - Global step: 514, Loss: 0.2634013994829729\n",
      "05/21/2022 10:55:33 - Global step: 515, Loss: 0.02903234155382961\n",
      "05/21/2022 10:55:35 - Global step: 516, Loss: 0.24984461306303274\n",
      "05/21/2022 10:55:37 - Global step: 517, Loss: 0.4890563209228276\n",
      "05/21/2022 10:55:39 - Global step: 518, Loss: 0.14337711385451257\n",
      "05/21/2022 10:55:42 - Global step: 519, Loss: 0.09338202127401019\n",
      "05/21/2022 10:55:44 - Global step: 520, Loss: 0.04306231637019664\n",
      "05/21/2022 10:55:46 - Global step: 521, Loss: 0.11119667903403752\n",
      "05/21/2022 10:55:49 - Global step: 522, Loss: 0.08551394348614849\n",
      "05/21/2022 10:55:51 - Global step: 523, Loss: 0.2959357659565285\n",
      "05/21/2022 10:55:53 - Global step: 524, Loss: 0.11024562080865508\n",
      "05/21/2022 10:55:56 - Global step: 525, Loss: 0.05084855548921041\n",
      "05/21/2022 10:55:58 - Global step: 526, Loss: 0.20666723677277332\n",
      "05/21/2022 10:56:00 - Global step: 527, Loss: 0.1648894282989204\n",
      "05/21/2022 10:56:03 - Global step: 528, Loss: 0.11798669822746888\n",
      "05/21/2022 10:56:05 - Global step: 529, Loss: 0.1483414156573417\n",
      "05/21/2022 10:56:07 - Global step: 530, Loss: 0.2040541053029301\n",
      "05/21/2022 10:56:10 - Global step: 531, Loss: 0.05145608537350199\n",
      "05/21/2022 10:56:12 - Global step: 532, Loss: 0.19835700326621009\n",
      "05/21/2022 10:56:14 - Global step: 533, Loss: 0.09265252078967023\n",
      "05/21/2022 10:56:17 - Global step: 534, Loss: 0.0757471752804122\n",
      "05/21/2022 10:56:19 - Global step: 535, Loss: 0.1928645500302082\n",
      "05/21/2022 10:56:21 - Global step: 536, Loss: 0.3663711171830073\n",
      "05/21/2022 10:56:24 - Global step: 537, Loss: 0.3293209922085225\n",
      "05/21/2022 10:56:26 - Global step: 538, Loss: 0.12955048341973452\n",
      "05/21/2022 10:56:28 - Global step: 539, Loss: 0.12289200796658406\n",
      "05/21/2022 10:56:30 - Global step: 540, Loss: 0.15149120669411786\n",
      "05/21/2022 10:56:33 - Global step: 541, Loss: 0.07930702311023197\n",
      "05/21/2022 10:56:35 - Global step: 542, Loss: 0.03993493837515416\n",
      "05/21/2022 10:56:37 - Global step: 543, Loss: 0.06016984848247375\n",
      "05/21/2022 10:56:40 - Global step: 544, Loss: 0.3077155820064945\n",
      "05/21/2022 10:56:42 - Global step: 545, Loss: 0.13675481815334933\n",
      "05/21/2022 10:56:44 - Global step: 546, Loss: 0.030621392506873235\n",
      "05/21/2022 10:56:47 - Global step: 547, Loss: 0.018540300467975612\n",
      "05/21/2022 10:56:49 - Global step: 548, Loss: 0.02748642541700974\n",
      "05/21/2022 10:56:51 - Global step: 549, Loss: 0.13804437115322798\n",
      "05/21/2022 10:56:54 - Global step: 550, Loss: 0.3612672159069916\n",
      "05/21/2022 10:56:56 - Global step: 551, Loss: 0.21274618631196063\n",
      "05/21/2022 10:56:58 - Global step: 552, Loss: 0.01961246352584567\n",
      "05/21/2022 10:57:01 - Global step: 553, Loss: 0.0707484836148069\n",
      "05/21/2022 10:57:03 - Global step: 554, Loss: 0.20301834596466506\n",
      "05/21/2022 10:57:05 - Global step: 555, Loss: 0.38280663335171994\n",
      "05/21/2022 10:57:08 - Global step: 556, Loss: 0.09601634318460128\n",
      "05/21/2022 10:57:10 - Global step: 557, Loss: 0.6985242145019583\n",
      "05/21/2022 10:57:12 - Global step: 558, Loss: 0.07838384774004226\n",
      "05/21/2022 10:57:15 - Global step: 559, Loss: 0.10631200709030963\n",
      "05/21/2022 10:57:17 - Global step: 560, Loss: 0.07135243921584333\n",
      "05/21/2022 10:57:19 - Global step: 561, Loss: 0.02757979450689163\n",
      "05/21/2022 10:57:21 - Global step: 562, Loss: 0.2550014758016914\n",
      "05/21/2022 10:57:24 - Global step: 563, Loss: 0.13633270061109215\n",
      "05/21/2022 10:57:26 - Global step: 564, Loss: 0.07747696223668754\n",
      "05/21/2022 10:57:28 - Global step: 565, Loss: 0.3368519162759185\n",
      "05/21/2022 10:57:31 - Global step: 566, Loss: 0.08313029454438947\n",
      "05/21/2022 10:57:33 - Global step: 567, Loss: 0.24355631018988788\n",
      "05/21/2022 10:57:35 - Global step: 568, Loss: 0.16488175257109106\n",
      "05/21/2022 10:57:38 - Global step: 569, Loss: 0.17041058779432205\n",
      "05/21/2022 10:57:40 - Global step: 570, Loss: 0.09863166027935222\n",
      "05/21/2022 10:57:42 - Global step: 571, Loss: 0.25994754608836956\n",
      "05/21/2022 10:57:45 - Global step: 572, Loss: 0.021755890491476748\n",
      "05/21/2022 10:57:47 - Global step: 573, Loss: 0.17343133687973022\n",
      "05/21/2022 10:57:49 - Global step: 574, Loss: 0.18924731756851543\n",
      "05/21/2022 10:57:52 - Global step: 575, Loss: 0.018206077569629997\n",
      "05/21/2022 10:57:54 - Global step: 576, Loss: 0.2554372645972762\n",
      "05/21/2022 10:57:56 - Global step: 577, Loss: 0.021661814615072217\n",
      "05/21/2022 10:57:59 - Global step: 578, Loss: 0.21783758321635105\n",
      "05/21/2022 10:58:01 - Global step: 579, Loss: 0.2855498530789191\n",
      "05/21/2022 10:58:03 - Global step: 580, Loss: 0.12758256572851678\n",
      "05/21/2022 10:58:06 - Global step: 581, Loss: 0.22483174046305976\n",
      "05/21/2022 10:58:08 - Global step: 582, Loss: 0.1836203682814812\n",
      "05/21/2022 10:58:10 - Global step: 583, Loss: 0.13158721332001733\n",
      "05/21/2022 10:58:13 - Global step: 584, Loss: 0.2090984817550634\n",
      "05/21/2022 10:58:15 - Global step: 585, Loss: 0.1314240641077049\n",
      "05/21/2022 10:58:17 - Global step: 586, Loss: 0.20680640486534685\n",
      "05/21/2022 10:58:20 - Global step: 587, Loss: 0.019935425494622905\n",
      "05/21/2022 10:58:22 - Global step: 588, Loss: 0.25776155618950725\n",
      "05/21/2022 10:58:24 - Global step: 589, Loss: 0.36263219588727225\n",
      "05/21/2022 10:58:26 - Global step: 590, Loss: 0.431965978109929\n",
      "05/21/2022 10:58:29 - Global step: 591, Loss: 0.41736954226507805\n",
      "05/21/2022 10:58:31 - Global step: 592, Loss: 0.18023800293303793\n",
      "05/21/2022 10:58:33 - Global step: 593, Loss: 0.027865312520589214\n",
      "05/21/2022 10:58:36 - Global step: 594, Loss: 0.004752723420097027\n",
      "05/21/2022 10:58:38 - Global step: 595, Loss: 0.07319508084037807\n",
      "05/21/2022 10:58:40 - Global step: 596, Loss: 0.0790782807089272\n",
      "05/21/2022 10:58:43 - Global step: 597, Loss: 0.10753027827013284\n",
      "05/21/2022 10:58:45 - Global step: 598, Loss: 0.25291240063961595\n",
      "05/21/2022 10:58:47 - Global step: 599, Loss: 0.0573172564872948\n",
      "05/21/2022 10:58:50 - Global step: 600, Loss: 0.17564169368415605\n",
      "05/21/2022 10:58:52 - Global step: 601, Loss: 0.1276719475754362\n",
      "05/21/2022 10:58:54 - Global step: 602, Loss: 0.4449968022745452\n",
      "05/21/2022 10:58:57 - Global step: 603, Loss: 0.1692313280509552\n",
      "05/21/2022 10:58:59 - Global step: 604, Loss: 0.4678786918811966\n",
      "05/21/2022 10:59:01 - Global step: 605, Loss: 0.03687357947092096\n",
      "05/21/2022 10:59:04 - Global step: 606, Loss: 0.18452595886628842\n",
      "05/21/2022 10:59:06 - Global step: 607, Loss: 0.20210874694748782\n",
      "05/21/2022 10:59:08 - Global step: 608, Loss: 0.028221929713254212\n",
      "05/21/2022 10:59:11 - Global step: 609, Loss: 0.1545906369574368\n",
      "05/21/2022 10:59:13 - Global step: 610, Loss: 0.40010560213704593\n",
      "05/21/2022 10:59:15 - Global step: 611, Loss: 0.8356274846137239\n",
      "05/21/2022 10:59:18 - Global step: 612, Loss: 0.015619399593560956\n",
      "05/21/2022 10:59:20 - Global step: 613, Loss: 0.16957569535588846\n",
      "05/21/2022 10:59:22 - Global step: 614, Loss: 0.14323666103882715\n",
      "05/21/2022 10:59:24 - Global step: 615, Loss: 0.44322714081499726\n",
      "05/21/2022 10:59:27 - Global step: 616, Loss: 0.22325830277986825\n",
      "05/21/2022 10:59:29 - Global step: 617, Loss: 0.1703785069694277\n",
      "05/21/2022 10:59:31 - Global step: 618, Loss: 0.06246884388383478\n",
      "05/21/2022 10:59:34 - Global step: 619, Loss: 0.1729917493648827\n",
      "05/21/2022 10:59:36 - Global step: 620, Loss: 0.1402500447584316\n",
      "05/21/2022 10:59:38 - Global step: 621, Loss: 0.09512568067293614\n",
      "05/21/2022 10:59:41 - Global step: 622, Loss: 0.2541010385029949\n",
      "05/21/2022 10:59:43 - Global step: 623, Loss: 0.03063237597234547\n",
      "05/21/2022 10:59:45 - Global step: 624, Loss: 0.1742340354830958\n",
      "05/21/2022 10:59:48 - Global step: 625, Loss: 0.3135258693364449\n",
      "05/21/2022 10:59:50 - Global step: 626, Loss: 0.28894647519337013\n",
      "05/21/2022 10:59:52 - Global step: 627, Loss: 0.23811485135229304\n",
      "05/21/2022 10:59:55 - Global step: 628, Loss: 0.05438342341949465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/21/2022 10:59:57 - Global step: 629, Loss: 0.0785906319069909\n",
      "05/21/2022 10:59:59 - Global step: 630, Loss: 0.2585785770788789\n",
      "05/21/2022 11:00:02 - Global step: 631, Loss: 0.2486669101053849\n",
      "05/21/2022 11:00:04 - Global step: 632, Loss: 0.0559340602485463\n",
      "05/21/2022 11:00:06 - Global step: 633, Loss: 0.32870767975691706\n",
      "05/21/2022 11:00:09 - Global step: 634, Loss: 0.04530520804109983\n",
      "05/21/2022 11:00:11 - Global step: 635, Loss: 0.2588593265900272\n",
      "05/21/2022 11:00:13 - Global step: 636, Loss: 0.062413792649749666\n",
      "05/21/2022 11:00:15 - Global step: 637, Loss: 0.11759487811650615\n",
      "05/21/2022 11:00:18 - Global step: 638, Loss: 0.14053544144553598\n",
      "05/21/2022 11:00:20 - Global step: 639, Loss: 0.04356586288213293\n",
      "05/21/2022 11:00:22 - Global step: 640, Loss: 0.07607316132634878\n",
      "05/21/2022 11:00:25 - Global step: 641, Loss: 0.07362454255780904\n",
      "05/21/2022 11:00:27 - Global step: 642, Loss: 0.14890435069492014\n",
      "05/21/2022 11:00:29 - Global step: 643, Loss: 0.0787349485217419\n",
      "05/21/2022 11:00:32 - Global step: 644, Loss: 0.17856149050203385\n",
      "05/21/2022 11:00:34 - Global step: 645, Loss: 0.10571596771569602\n",
      "05/21/2022 11:00:36 - Global step: 646, Loss: 0.020393648759636562\n",
      "05/21/2022 11:00:39 - Global step: 647, Loss: 0.01637600746471435\n",
      "05/21/2022 11:00:41 - Global step: 648, Loss: 0.26685598135554756\n",
      "05/21/2022 11:00:43 - Global step: 649, Loss: 0.03265022764389869\n",
      "05/21/2022 11:00:46 - Global step: 650, Loss: 0.10357780080812518\n",
      "05/21/2022 11:00:48 - Global step: 651, Loss: 0.4999636337397533\n",
      "05/21/2022 11:00:50 - Global step: 652, Loss: 0.019231050140660955\n",
      "05/21/2022 11:00:53 - Global step: 653, Loss: 0.0706214808524237\n",
      "05/21/2022 11:00:55 - Global step: 654, Loss: 0.19342720546706005\n",
      "05/21/2022 11:00:57 - Global step: 655, Loss: 0.5829764038662688\n",
      "05/21/2022 11:01:00 - Global step: 656, Loss: 0.3693264269031715\n",
      "05/21/2022 11:01:02 - Global step: 657, Loss: 0.061240825614731875\n",
      "05/21/2022 11:01:04 - Global step: 658, Loss: 0.17019474010157865\n",
      "05/21/2022 11:01:07 - Global step: 659, Loss: 0.1763013389063417\n",
      "05/21/2022 11:01:09 - Global step: 660, Loss: 0.3977716140798293\n",
      "05/21/2022 11:01:11 - Global step: 661, Loss: 0.10122559430601541\n",
      "05/21/2022 11:01:14 - Global step: 662, Loss: 0.3334826073014483\n",
      "05/21/2022 11:01:16 - Global step: 663, Loss: 0.025507976144581335\n",
      "05/21/2022 11:01:18 - Global step: 664, Loss: 0.415204330070992\n",
      "05/21/2022 11:01:21 - Global step: 665, Loss: 0.1508109502537991\n",
      "05/21/2022 11:01:23 - Global step: 666, Loss: 0.17110692532151006\n",
      "05/21/2022 11:01:25 - Global step: 667, Loss: 0.40869346399995266\n",
      "05/21/2022 11:01:28 - Global step: 668, Loss: 0.09658202588616405\n",
      "05/21/2022 11:01:30 - Global step: 669, Loss: 0.11420754506252706\n",
      "05/21/2022 11:01:32 - Global step: 670, Loss: 0.08780608593951911\n",
      "05/21/2022 11:01:34 - Global step: 671, Loss: 0.1485221428629302\n",
      "05/21/2022 11:01:37 - Global step: 672, Loss: 0.3166891615255736\n",
      "05/21/2022 11:01:39 - Global step: 673, Loss: 0.0562366604062845\n",
      "05/21/2022 11:01:41 - Global step: 674, Loss: 0.06070454074506415\n",
      "05/21/2022 11:01:44 - Global step: 675, Loss: 0.04946225621824851\n",
      "05/21/2022 11:01:46 - Global step: 676, Loss: 0.22046494102687575\n",
      "05/21/2022 11:01:48 - Global step: 677, Loss: 0.09699590783566236\n",
      "05/21/2022 11:01:51 - Global step: 678, Loss: 0.2765530583765212\n",
      "05/21/2022 11:01:53 - Global step: 679, Loss: 0.16471223116968758\n",
      "05/21/2022 11:01:55 - Global step: 680, Loss: 0.3738096050801687\n",
      "05/21/2022 11:01:58 - Global step: 681, Loss: 0.050902339949971065\n",
      "05/21/2022 11:02:00 - Global step: 682, Loss: 0.18114741225872422\n",
      "05/21/2022 11:02:02 - Global step: 683, Loss: 0.24384991498664021\n",
      "05/21/2022 11:02:05 - Global step: 684, Loss: 0.2026255176460836\n",
      "05/21/2022 11:02:07 - Global step: 685, Loss: 0.46584305725991726\n",
      "05/21/2022 11:02:09 - Global step: 686, Loss: 0.03118312160950154\n",
      "05/21/2022 11:02:12 - Global step: 687, Loss: 0.08187115090549923\n",
      "05/21/2022 11:02:14 - Global step: 688, Loss: 0.16826910531381145\n",
      "05/21/2022 11:02:16 - Global step: 689, Loss: 0.16860337951220572\n",
      "05/21/2022 11:02:19 - Global step: 690, Loss: 0.2347880220913794\n",
      "05/21/2022 11:02:21 - Global step: 691, Loss: 0.1167618363906513\n",
      "05/21/2022 11:02:23 - Global step: 692, Loss: 0.1864107007277198\n",
      "05/21/2022 11:02:25 - Global step: 693, Loss: 0.11856580001040129\n",
      "05/21/2022 11:02:28 - Global step: 694, Loss: 0.30002022156259045\n",
      "05/21/2022 11:02:30 - Global step: 695, Loss: 0.05554412704077549\n",
      "05/21/2022 11:02:32 - Global step: 696, Loss: 0.05682833255195874\n",
      "05/21/2022 11:02:35 - Global step: 697, Loss: 0.2213872427964816\n",
      "05/21/2022 11:02:37 - Global step: 698, Loss: 0.061188669787952676\n",
      "05/21/2022 11:02:39 - Global step: 699, Loss: 0.2088906189019326\n",
      "05/21/2022 11:02:42 - Global step: 700, Loss: 0.3416856818830638\n",
      "05/21/2022 11:02:44 - Global step: 701, Loss: 0.11307021084940061\n",
      "05/21/2022 11:02:46 - Global step: 702, Loss: 0.013055003590125125\n",
      "05/21/2022 11:02:49 - Global step: 703, Loss: 0.08770463601103984\n",
      "05/21/2022 11:02:51 - Global step: 704, Loss: 0.3373905867756548\n",
      "05/21/2022 11:02:53 - Global step: 705, Loss: 0.20642206874254043\n",
      "05/21/2022 11:02:56 - Global step: 706, Loss: 0.6496709499697317\n",
      "05/21/2022 11:02:58 - Global step: 707, Loss: 0.28117373131499335\n",
      "05/21/2022 11:03:00 - Global step: 708, Loss: 0.07849414830434398\n",
      "05/21/2022 11:03:03 - Global step: 709, Loss: 0.35802386558589205\n",
      "05/21/2022 11:03:05 - Global step: 710, Loss: 0.2647499404847622\n",
      "05/21/2022 11:03:07 - Global step: 711, Loss: 0.3208413332058626\n",
      "05/21/2022 11:03:10 - Global step: 712, Loss: 0.1770548111635435\n",
      "05/21/2022 11:03:12 - Global step: 713, Loss: 0.04361577875170042\n",
      "05/21/2022 11:03:14 - Global step: 714, Loss: 0.26354163492578664\n",
      "05/21/2022 11:03:17 - Global step: 715, Loss: 0.8541724177193828\n",
      "05/21/2022 11:03:19 - Global step: 716, Loss: 0.2095259394554887\n",
      "05/21/2022 11:03:21 - Global step: 717, Loss: 0.08746975366375409\n",
      "05/21/2022 11:03:24 - Global step: 718, Loss: 0.016639813176880125\n",
      "05/21/2022 11:03:26 - Global step: 719, Loss: 0.11748180878930725\n",
      "05/21/2022 11:03:28 - Global step: 720, Loss: 0.19179244991391897\n",
      "05/21/2022 11:03:31 - Global step: 721, Loss: 0.23169930162839592\n",
      "05/21/2022 11:03:33 - Global step: 722, Loss: 0.29817921144422144\n",
      "05/21/2022 11:03:35 - Global step: 723, Loss: 0.16637882059148978\n",
      "05/21/2022 11:03:38 - Global step: 724, Loss: 0.14695535862119868\n",
      "05/21/2022 11:03:40 - Global step: 725, Loss: 0.17650571891499567\n",
      "05/21/2022 11:03:42 - Global step: 726, Loss: 0.1255178564460948\n",
      "05/21/2022 11:03:45 - Global step: 727, Loss: 0.26355377811705694\n",
      "05/21/2022 11:03:47 - Global step: 728, Loss: 0.04729474247142207\n",
      "05/21/2022 11:03:49 - Global step: 729, Loss: 0.02109051265870221\n",
      "05/21/2022 11:03:51 - Global step: 730, Loss: 0.4590768421185203\n",
      "05/21/2022 11:03:54 - Global step: 731, Loss: 0.5405574500764487\n",
      "05/21/2022 11:03:56 - Global step: 732, Loss: 0.10661609533417504\n",
      "05/21/2022 11:03:58 - Global step: 733, Loss: 0.616244948017993\n",
      "05/21/2022 11:04:01 - Global step: 734, Loss: 0.08316644909791648\n",
      "05/21/2022 11:04:03 - Global step: 735, Loss: 0.6119000419275835\n",
      "05/21/2022 11:04:05 - Global step: 736, Loss: 0.17610878392588347\n",
      "05/21/2022 11:04:08 - Global step: 737, Loss: 0.11697915440890938\n",
      "05/21/2022 11:04:10 - Global step: 738, Loss: 0.32227958377916366\n",
      "05/21/2022 11:04:12 - Global step: 739, Loss: 0.07628787093563005\n",
      "05/21/2022 11:04:15 - Global step: 740, Loss: 0.21905258222250268\n",
      "05/21/2022 11:04:17 - Global step: 741, Loss: 0.21259438851848245\n",
      "05/21/2022 11:04:19 - Global step: 742, Loss: 0.06614553299732506\n",
      "05/21/2022 11:04:22 - Global step: 743, Loss: 0.11869880446465686\n",
      "05/21/2022 11:04:24 - Global step: 744, Loss: 0.0937464477319736\n",
      "05/21/2022 11:04:26 - Global step: 745, Loss: 0.18785943172406405\n",
      "05/21/2022 11:04:29 - Global step: 746, Loss: 0.3147353759704856\n",
      "05/21/2022 11:04:31 - Global step: 747, Loss: 0.6222825103905052\n",
      "05/21/2022 11:04:33 - Global step: 748, Loss: 0.3523542403563624\n",
      "05/21/2022 11:04:36 - Global step: 749, Loss: 0.09683239192236215\n",
      "05/21/2022 11:04:38 - Global step: 750, Loss: 0.25828391214599833\n",
      "05/21/2022 11:04:40 - Global step: 751, Loss: 0.04093640267092269\n",
      "05/21/2022 11:04:43 - Global step: 752, Loss: 0.9054101634537801\n",
      "05/21/2022 11:04:45 - Global step: 753, Loss: 0.24992515670601279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/21/2022 11:04:47 - Global step: 754, Loss: 0.026929212704999372\n",
      "05/21/2022 11:04:49 - Global step: 755, Loss: 0.18995574832661077\n",
      "05/21/2022 11:04:52 - Global step: 756, Loss: 0.07256829820107669\n",
      "05/21/2022 11:04:54 - Global step: 757, Loss: 0.16431504496722482\n",
      "05/21/2022 11:04:56 - Global step: 758, Loss: 0.31096344883553684\n",
      "05/21/2022 11:04:59 - Global step: 759, Loss: 0.24147161620203406\n",
      "05/21/2022 11:05:01 - Global step: 760, Loss: 0.1610870903241448\n",
      "05/21/2022 11:05:03 - Global step: 761, Loss: 0.1112115575815551\n",
      "05/21/2022 11:05:06 - Global step: 762, Loss: 0.17138411826454103\n",
      "05/21/2022 11:05:08 - Global step: 763, Loss: 0.026788369403220713\n",
      "05/21/2022 11:05:10 - Global step: 764, Loss: 0.14508904237300158\n",
      "05/21/2022 11:05:13 - Global step: 765, Loss: 0.23203249255311675\n",
      "05/21/2022 11:05:15 - Global step: 766, Loss: 0.5400923965062248\n",
      "05/21/2022 11:05:17 - Global step: 767, Loss: 0.6901648856583051\n",
      "05/21/2022 11:05:20 - Global step: 768, Loss: 0.2986901144613512\n",
      "05/21/2022 11:05:22 - Global step: 769, Loss: 0.05874819371092599\n",
      "05/21/2022 11:05:24 - Global step: 770, Loss: 0.02930446389655117\n",
      "05/21/2022 11:05:27 - Global step: 771, Loss: 0.49338292083120905\n",
      "05/21/2022 11:05:29 - Global step: 772, Loss: 0.17346569005167112\n",
      "05/21/2022 11:05:31 - Global step: 773, Loss: 0.4841480382019654\n",
      "05/21/2022 11:05:34 - Global step: 774, Loss: 0.25258812471292913\n",
      "05/21/2022 11:05:36 - Global step: 775, Loss: 0.18666196847334504\n",
      "05/21/2022 11:05:38 - Global step: 776, Loss: 0.04622912034392357\n",
      "05/21/2022 11:05:40 - Global step: 777, Loss: 0.3599836796056479\n",
      "05/21/2022 11:05:43 - Global step: 778, Loss: 0.07992378153721802\n",
      "05/21/2022 11:05:45 - Global step: 779, Loss: 0.11079401045572013\n",
      "05/21/2022 11:05:47 - Global step: 780, Loss: 0.1750729309860617\n",
      "05/21/2022 11:05:50 - Global step: 781, Loss: 0.3167985308682546\n",
      "05/21/2022 11:05:52 - Global step: 782, Loss: 0.148250091355294\n",
      "05/21/2022 11:05:54 - Global step: 783, Loss: 0.1020482879539486\n",
      "05/21/2022 11:05:57 - Global step: 784, Loss: 0.1321082030190155\n",
      "05/21/2022 11:05:59 - Global step: 785, Loss: 0.07713096676161513\n",
      "05/21/2022 11:06:01 - Global step: 786, Loss: 0.11912536597810686\n",
      "05/21/2022 11:06:04 - Global step: 787, Loss: 0.09134323103353381\n",
      "05/21/2022 11:06:06 - Global step: 788, Loss: 0.21461597946472466\n",
      "05/21/2022 11:06:08 - Global step: 789, Loss: 0.2213194710056996\n",
      "05/21/2022 11:06:11 - Global step: 790, Loss: 0.03558097974746488\n",
      "05/21/2022 11:06:13 - Global step: 791, Loss: 0.06901428417040734\n",
      "05/21/2022 11:06:15 - Global step: 792, Loss: 0.25886739816633053\n",
      "05/21/2022 11:06:18 - Global step: 793, Loss: 0.18731472286162898\n",
      "05/21/2022 11:06:20 - Global step: 794, Loss: 0.031674604113504756\n",
      "05/21/2022 11:06:22 - Global step: 795, Loss: 0.45544630591757596\n",
      "05/21/2022 11:06:25 - Global step: 796, Loss: 0.22378678371023852\n",
      "05/21/2022 11:06:27 - Global step: 797, Loss: 0.12057864014786901\n",
      "05/21/2022 11:06:29 - Global step: 798, Loss: 0.053709715753939236\n",
      "05/21/2022 11:06:32 - Global step: 799, Loss: 0.09532954546739347\n",
      "05/21/2022 11:06:34 - Global step: 800, Loss: 0.21865203430934343\n",
      "05/21/2022 11:06:36 - Global step: 801, Loss: 0.0599289279198274\n",
      "05/21/2022 11:06:38 - Global step: 802, Loss: 0.23279600440946524\n",
      "05/21/2022 11:06:41 - Global step: 803, Loss: 0.13471832365030423\n",
      "05/21/2022 11:06:43 - Global step: 804, Loss: 0.08963796481839381\n",
      "05/21/2022 11:06:45 - Global step: 805, Loss: 0.09029462466060068\n",
      "05/21/2022 11:06:48 - Global step: 806, Loss: 0.04480506421532482\n",
      "05/21/2022 11:06:50 - Global step: 807, Loss: 0.15659000870073214\n",
      "05/21/2022 11:06:52 - Global step: 808, Loss: 0.27480840991484\n",
      "05/21/2022 11:06:55 - Global step: 809, Loss: 0.07982577961229254\n",
      "05/21/2022 11:06:57 - Global step: 810, Loss: 0.1197667863452807\n",
      "05/21/2022 11:06:59 - Global step: 811, Loss: 0.09004248710698448\n",
      "05/21/2022 11:07:02 - Global step: 812, Loss: 0.04700717607192928\n",
      "05/21/2022 11:07:04 - Global step: 813, Loss: 0.13633761385608523\n",
      "05/21/2022 11:07:06 - Global step: 814, Loss: 0.032589870286756195\n",
      "05/21/2022 11:07:09 - Global step: 815, Loss: 0.01904383830333245\n",
      "05/21/2022 11:07:11 - Global step: 816, Loss: 0.14973044313956052\n",
      "05/21/2022 11:07:13 - Global step: 817, Loss: 0.2723176554427482\n",
      "05/21/2022 11:07:16 - Global step: 818, Loss: 0.2282852739763257\n",
      "05/21/2022 11:07:18 - Global step: 819, Loss: 0.12355952090729261\n",
      "05/21/2022 11:07:20 - Global step: 820, Loss: 0.01646255848754663\n",
      "05/21/2022 11:07:23 - Global step: 821, Loss: 0.04413424622180173\n",
      "05/21/2022 11:07:25 - Global step: 822, Loss: 0.02909875611476309\n",
      "05/21/2022 11:07:27 - Global step: 823, Loss: 0.07227088901709067\n",
      "05/21/2022 11:07:30 - Global step: 824, Loss: 0.0982704486568764\n",
      "05/21/2022 11:07:32 - Global step: 825, Loss: 0.03712827478921099\n",
      "05/21/2022 11:07:34 - Global step: 826, Loss: 0.1225968277103675\n",
      "05/21/2022 11:07:36 - Global step: 827, Loss: 0.10574956833806937\n",
      "05/21/2022 11:07:39 - Global step: 828, Loss: 0.20595428499836999\n",
      "05/21/2022 11:07:41 - Global step: 829, Loss: 0.5010626648945617\n",
      "05/21/2022 11:07:43 - Global step: 830, Loss: 0.0776647137981854\n",
      "05/21/2022 11:07:46 - Global step: 831, Loss: 0.24557358473475688\n",
      "05/21/2022 11:07:48 - Global step: 832, Loss: 0.4329980281299868\n",
      "05/21/2022 11:07:50 - Global step: 833, Loss: 0.011478692530999979\n",
      "05/21/2022 11:07:53 - Global step: 834, Loss: 0.19666750205942662\n",
      "05/21/2022 11:07:55 - Global step: 835, Loss: 0.4238640686235158\n",
      "05/21/2022 11:07:57 - Global step: 836, Loss: 0.04121278545426321\n",
      "05/21/2022 11:08:00 - Global step: 837, Loss: 0.18444977519538952\n",
      "05/21/2022 11:08:02 - Global step: 838, Loss: 0.02388958872506919\n",
      "05/21/2022 11:08:04 - Global step: 839, Loss: 0.14055367388937157\n",
      "05/21/2022 11:08:07 - Global step: 840, Loss: 0.3103112725948449\n",
      "05/21/2022 11:08:09 - Global step: 841, Loss: 0.02369480926427059\n",
      "05/21/2022 11:08:11 - Global step: 842, Loss: 0.15867706672361237\n",
      "05/21/2022 11:08:14 - Global step: 843, Loss: 0.013480491543305106\n",
      "05/21/2022 11:08:16 - Global step: 844, Loss: 0.5596154829254374\n",
      "05/21/2022 11:08:18 - Global step: 845, Loss: 0.06719176027399953\n",
      "05/21/2022 11:08:21 - Global step: 846, Loss: 0.17818576039280742\n",
      "05/21/2022 11:08:23 - Global step: 847, Loss: 0.12911886791698635\n",
      "05/21/2022 11:08:25 - Global step: 848, Loss: 0.053840081789530814\n",
      "05/21/2022 11:08:28 - Global step: 849, Loss: 0.16776723391376436\n",
      "05/21/2022 11:08:30 - Global step: 850, Loss: 0.07000005163718015\n",
      "05/21/2022 11:08:32 - Global step: 851, Loss: 0.0782393233384937\n",
      "05/21/2022 11:08:35 - Global step: 852, Loss: 0.009719279245473444\n",
      "05/21/2022 11:08:37 - Global step: 853, Loss: 0.12263061298290268\n",
      "05/21/2022 11:08:39 - Global step: 854, Loss: 0.16614775895141065\n",
      "05/21/2022 11:08:42 - Global step: 855, Loss: 0.07921965887362603\n",
      "05/21/2022 11:08:44 - Global step: 856, Loss: 0.04101699325838126\n",
      "05/21/2022 11:08:46 - Global step: 857, Loss: 0.05477227312803734\n",
      "05/21/2022 11:08:49 - Global step: 858, Loss: 0.044390657647454645\n",
      "05/21/2022 11:08:51 - Global step: 859, Loss: 0.2630068337311968\n",
      "05/21/2022 11:08:53 - Global step: 860, Loss: 0.08569234898095601\n",
      "05/21/2022 11:08:56 - Global step: 861, Loss: 0.10727784421760589\n",
      "05/21/2022 11:08:58 - Global step: 862, Loss: 0.3258067929673416\n",
      "05/21/2022 11:09:00 - Global step: 863, Loss: 0.45850883623097616\n",
      "05/21/2022 11:09:03 - Global step: 864, Loss: 0.15996158667985583\n",
      "05/21/2022 11:09:05 - Global step: 865, Loss: 0.3405399586263229\n",
      "05/21/2022 11:09:07 - Global step: 866, Loss: 0.15433533504165098\n",
      "05/21/2022 11:09:10 - Global step: 867, Loss: 0.06710961987846531\n",
      "05/21/2022 11:09:12 - Global step: 868, Loss: 0.1780125205841614\n",
      "05/21/2022 11:09:14 - Global step: 869, Loss: 0.1661330996430479\n",
      "05/21/2022 11:09:17 - Global step: 870, Loss: 0.20345261832335382\n",
      "05/21/2022 11:09:19 - Global step: 871, Loss: 0.030241242406191304\n",
      "05/21/2022 11:09:21 - Global step: 872, Loss: 0.11547708989382954\n",
      "05/21/2022 11:09:24 - Global step: 873, Loss: 0.03591857303035795\n",
      "05/21/2022 11:09:26 - Global step: 874, Loss: 0.1093774278415367\n",
      "05/21/2022 11:09:28 - Global step: 875, Loss: 0.08197759080212563\n",
      "05/21/2022 11:09:30 - Global step: 876, Loss: 0.14709837980990415\n",
      "05/21/2022 11:09:33 - Global step: 877, Loss: 0.005972455568553414\n",
      "05/21/2022 11:09:35 - Global step: 878, Loss: 0.3667415310519573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/21/2022 11:09:37 - Global step: 879, Loss: 0.20120184117695317\n",
      "05/21/2022 11:09:40 - Global step: 880, Loss: 0.09800453330535674\n",
      "05/21/2022 11:09:42 - Global step: 881, Loss: 0.3664973384074983\n",
      "05/21/2022 11:09:44 - Global step: 882, Loss: 0.020068632264155895\n",
      "05/21/2022 11:09:47 - Global step: 883, Loss: 0.3712906498162738\n",
      "05/21/2022 11:09:49 - Global step: 884, Loss: 0.4102043910534121\n",
      "05/21/2022 11:09:51 - Global step: 885, Loss: 0.028481008091148396\n",
      "05/21/2022 11:09:54 - Global step: 886, Loss: 0.08768598707501951\n",
      "05/21/2022 11:09:56 - Global step: 887, Loss: 0.2399840670186677\n",
      "05/21/2022 11:09:59 - Global step: 888, Loss: 0.530847582827846\n",
      "05/21/2022 11:10:01 - Global step: 889, Loss: 0.12411515983694699\n",
      "05/21/2022 11:10:03 - Global step: 890, Loss: 0.04500972353707766\n",
      "05/21/2022 11:10:05 - Global step: 891, Loss: 0.1835501075256616\n",
      "05/21/2022 11:10:08 - Global step: 892, Loss: 0.18848116826848127\n",
      "05/21/2022 11:10:10 - Global step: 893, Loss: 0.120979046827415\n",
      "05/21/2022 11:10:12 - Global step: 894, Loss: 0.17700440814951435\n",
      "05/21/2022 11:10:15 - Global step: 895, Loss: 0.11168045992963016\n",
      "05/21/2022 11:10:17 - Global step: 896, Loss: 0.053928260607790435\n",
      "05/21/2022 11:10:19 - Global step: 897, Loss: 0.07475536916172132\n",
      "05/21/2022 11:10:22 - Global step: 898, Loss: 0.15279577926776255\n",
      "05/21/2022 11:10:24 - Global step: 899, Loss: 0.023798533471563132\n",
      "05/21/2022 11:10:26 - Global step: 900, Loss: 0.08262931332137669\n",
      "05/21/2022 11:10:29 - Global step: 901, Loss: 0.17419812727894168\n",
      "05/21/2022 11:10:31 - Global step: 902, Loss: 0.34557487489291816\n",
      "05/21/2022 11:10:33 - Global step: 903, Loss: 0.21644687896059622\n",
      "05/21/2022 11:10:36 - Global step: 904, Loss: 0.020764216722454876\n",
      "05/21/2022 11:10:38 - Global step: 905, Loss: 0.25782357298521674\n",
      "05/21/2022 11:10:40 - Global step: 906, Loss: 0.045416537272103596\n",
      "05/21/2022 11:10:43 - Global step: 907, Loss: 0.026228846923913807\n",
      "05/21/2022 11:10:45 - Global step: 908, Loss: 0.1230844502333639\n",
      "05/21/2022 11:10:47 - Global step: 909, Loss: 0.3317198106160504\n",
      "05/21/2022 11:10:50 - Global step: 910, Loss: 0.28914875539521745\n",
      "05/21/2022 11:10:52 - Global step: 911, Loss: 0.07507019441982266\n",
      "05/21/2022 11:10:54 - Global step: 912, Loss: 0.084258892784419\n",
      "05/21/2022 11:10:57 - Global step: 913, Loss: 0.0973681643808959\n",
      "05/21/2022 11:10:59 - Global step: 914, Loss: 0.34742599001765484\n",
      "05/21/2022 11:11:01 - Global step: 915, Loss: 0.3521541628870182\n",
      "05/21/2022 11:11:04 - Global step: 916, Loss: 0.21283413855235267\n",
      "05/21/2022 11:11:06 - Global step: 917, Loss: 0.02021513888030313\n",
      "05/21/2022 11:11:08 - Global step: 918, Loss: 0.18006553407758474\n",
      "05/21/2022 11:11:11 - Global step: 919, Loss: 0.08346672073821537\n",
      "05/21/2022 11:11:13 - Global step: 920, Loss: 0.15149618555733468\n",
      "05/21/2022 11:11:15 - Global step: 921, Loss: 0.1798092166427523\n",
      "05/21/2022 11:11:18 - Global step: 922, Loss: 0.059881845430936664\n",
      "05/21/2022 11:11:20 - Global step: 923, Loss: 0.21861393422295805\n",
      "05/21/2022 11:11:22 - Global step: 924, Loss: 0.14816640206845477\n",
      "05/21/2022 11:11:25 - Global step: 925, Loss: 0.07429392354606534\n",
      "05/21/2022 11:11:27 - Global step: 926, Loss: 0.010810735839186236\n",
      "05/21/2022 11:11:29 - Global step: 927, Loss: 0.14751584107762028\n",
      "05/21/2022 11:11:32 - Global step: 928, Loss: 0.17678392351444927\n",
      "05/21/2022 11:11:34 - Global step: 929, Loss: 0.05292936653131619\n",
      "05/21/2022 11:11:36 - Global step: 930, Loss: 0.04704958824731875\n",
      "05/21/2022 11:11:39 - Global step: 931, Loss: 0.5155760974321311\n",
      "05/21/2022 11:11:41 - Global step: 932, Loss: 0.03334658260973811\n",
      "05/21/2022 11:11:43 - Global step: 933, Loss: 0.6235264459974132\n",
      "05/21/2022 11:11:46 - Global step: 934, Loss: 0.07113290971756214\n",
      "05/21/2022 11:11:48 - Global step: 935, Loss: 0.21982392097925185\n",
      "05/21/2022 11:11:50 - Global step: 936, Loss: 0.06518053781474009\n",
      "05/21/2022 11:11:53 - Global step: 937, Loss: 0.2070069440160296\n",
      "05/21/2022 11:11:55 - Global step: 938, Loss: 0.06221317602103227\n",
      "05/21/2022 11:11:57 - Global step: 939, Loss: 0.16316323133651167\n",
      "05/21/2022 11:12:00 - Global step: 940, Loss: 0.17353233127505518\n",
      "05/21/2022 11:12:02 - Global step: 941, Loss: 0.24837362366815796\n",
      "05/21/2022 11:12:04 - Global step: 942, Loss: 0.010579644191238913\n",
      "05/21/2022 11:12:07 - Global step: 943, Loss: 0.3964762045943644\n",
      "05/21/2022 11:12:09 - Global step: 944, Loss: 0.058704716815555\n",
      "05/21/2022 11:12:11 - Global step: 945, Loss: 0.21137024904601276\n",
      "05/21/2022 11:12:14 - Global step: 946, Loss: 0.024846040600095876\n",
      "05/21/2022 11:12:16 - Global step: 947, Loss: 0.044137370510725304\n",
      "05/21/2022 11:12:18 - Global step: 948, Loss: 0.07065085164504126\n",
      "05/21/2022 11:12:21 - Global step: 949, Loss: 0.14499809945118614\n",
      "05/21/2022 11:12:23 - Global step: 950, Loss: 0.43578871054023693\n",
      "05/21/2022 11:12:25 - Global step: 951, Loss: 0.025086678154366382\n",
      "05/21/2022 11:12:27 - Global step: 952, Loss: 0.06085597108176444\n",
      "05/21/2022 11:12:30 - Global step: 953, Loss: 0.21844713801692706\n",
      "05/21/2022 11:12:32 - Global step: 954, Loss: 0.14978624663672235\n",
      "05/21/2022 11:12:35 - Global step: 955, Loss: 0.02315382452798076\n",
      "05/21/2022 11:12:37 - Global step: 956, Loss: 0.1931142665519019\n",
      "05/21/2022 11:12:39 - Global step: 957, Loss: 0.08040756935952231\n",
      "05/21/2022 11:12:41 - Global step: 958, Loss: 0.3260160911886487\n",
      "05/21/2022 11:12:44 - Global step: 959, Loss: 0.9848939359217184\n",
      "05/21/2022 11:12:46 - Global step: 960, Loss: 0.10243152421026025\n",
      "05/21/2022 11:12:48 - Global step: 961, Loss: 0.23046857315057423\n",
      "05/21/2022 11:12:51 - Global step: 962, Loss: 0.19814188437885605\n",
      "05/21/2022 11:12:53 - Global step: 963, Loss: 0.40899604379956145\n",
      "05/21/2022 11:12:55 - Global step: 964, Loss: 0.04728158030775376\n",
      "05/21/2022 11:12:58 - Global step: 965, Loss: 0.13362701433652546\n",
      "05/21/2022 11:13:00 - Global step: 966, Loss: 0.03918832226190716\n",
      "05/21/2022 11:13:02 - Global step: 967, Loss: 0.19697971653658897\n",
      "05/21/2022 11:13:05 - Global step: 968, Loss: 0.16841934964759275\n",
      "05/21/2022 11:13:07 - Global step: 969, Loss: 0.23898779890441801\n",
      "05/21/2022 11:13:09 - Global step: 970, Loss: 0.08435309701599181\n",
      "05/21/2022 11:13:12 - Global step: 971, Loss: 0.15189319557975978\n",
      "05/21/2022 11:13:14 - Global step: 972, Loss: 0.46996353680151515\n",
      "05/21/2022 11:13:16 - Global step: 973, Loss: 0.021834677027072757\n",
      "05/21/2022 11:13:19 - Global step: 974, Loss: 0.2451007799245417\n",
      "05/21/2022 11:13:21 - Global step: 975, Loss: 0.6097179515090829\n",
      "05/21/2022 11:13:23 - Global step: 976, Loss: 0.24414809058362152\n",
      "05/21/2022 11:13:26 - Global step: 977, Loss: 0.2516167538706213\n",
      "05/21/2022 11:13:28 - Global step: 978, Loss: 0.23099920543609187\n",
      "05/21/2022 11:13:30 - Global step: 979, Loss: 0.07700034893059637\n",
      "05/21/2022 11:13:33 - Global step: 980, Loss: 0.19455108177498914\n",
      "05/21/2022 11:13:35 - Global step: 981, Loss: 0.13865426283155102\n",
      "05/21/2022 11:13:37 - Global step: 982, Loss: 0.2278785242815502\n",
      "05/21/2022 11:13:40 - Global step: 983, Loss: 0.02128641278250143\n",
      "05/21/2022 11:13:42 - Global step: 984, Loss: 0.0941132219741121\n",
      "05/21/2022 11:13:44 - Global step: 985, Loss: 0.04645377126871608\n",
      "05/21/2022 11:13:47 - Global step: 986, Loss: 0.15770666105890996\n",
      "05/21/2022 11:13:49 - Global step: 987, Loss: 0.17833774769678712\n",
      "05/21/2022 11:13:51 - Global step: 988, Loss: 0.013526558002922684\n",
      "05/21/2022 11:13:54 - Global step: 989, Loss: 0.01768283179262653\n",
      "05/21/2022 11:13:56 - Global step: 990, Loss: 0.3265697683327744\n",
      "05/21/2022 11:13:58 - Global step: 991, Loss: 0.05556480910490791\n",
      "05/21/2022 11:14:01 - Global step: 992, Loss: 0.3554321798692399\n",
      "05/21/2022 11:14:03 - Global step: 993, Loss: 0.028298574114160147\n",
      "05/21/2022 11:14:05 - Global step: 994, Loss: 0.048455569452926284\n",
      "05/21/2022 11:14:07 - Global step: 995, Loss: 0.07641597234396613\n",
      "05/21/2022 11:14:10 - Global step: 996, Loss: 0.08161102915346419\n",
      "05/21/2022 11:14:12 - Global step: 997, Loss: 0.3590254908449424\n",
      "05/21/2022 11:14:14 - Global step: 998, Loss: 0.022282821857515955\n",
      "05/21/2022 11:14:17 - Global step: 999, Loss: 0.0057987433319794945\n",
      "05/21/2022 11:14:19 - Global step: 1000, Loss: 0.1420679353491323\n",
      "05/21/2022 11:14:19 - Save for step global_step 1000\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 4772/4772 [26:07<00:00,  3.04it/s]\n",
      "05/21/2022 11:40:30 - Running Test data: 1080, with batch_size: 1, total batches: 1080.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reload pretrained entity embeddings from saved_model-LOG_sp_3_hsp_0_bz_16_lr_5e-05_score_dot_loss_nll_name_False_loc_False_maxloc_5_dist_False_dw_0.1_haversine_False_seed_42_cluster_0_trainfile_train_loc.json_testfile_test_loc.json_distilbert-base-uncased_entity_emb.np: 114520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1080/1080 [00:24<00:00, 43.66it/s]\n",
      "05/21/2022 11:40:55 - ----------\n",
      "05/21/2022 11:40:55 - Eval results on step-1000 -- acc@1: 1.7592592592592593\n",
      "05/21/2022 11:40:55 - Eval results on step-1000 -- acc@3: 5.277777777777778\n",
      "05/21/2022 11:40:55 - Eval results on step-1000 -- acc@5: 7.314814814814814\n",
      "05/21/2022 11:40:55 - Eval results on step-1000 -- acc@30: 27.314814814814813\n",
      "05/21/2022 11:40:55 - Eval results on step-1000 -- mrr: 0.05783221310840621\n",
      "05/21/2022 11:40:55 - Eval results on step-1000 -- size: 5957.468518518518\n",
      "05/21/2022 11:40:55 - Eval results on step-1000 -- gold_size: 2.0185185185185186\n",
      "05/21/2022 11:40:55 - Eval results on step-1000 -- std_acc@1: 0.0\n",
      "05/21/2022 11:40:55 - Eval results on step-1000 -- std_acc@3: 0.0\n",
      "05/21/2022 11:40:55 - Eval results on step-1000 -- std_acc@5: 0.0\n",
      "05/21/2022 11:40:55 - Eval results on step-1000 -- std_acc@30: 0.0\n",
      "05/21/2022 11:40:55 - Eval results on step-1000 -- std_mrr: 0.0\n",
      "05/21/2022 11:40:55 - Eval results on step-1000 -- std_size: 0.0\n",
      "05/21/2022 11:40:55 - ----------\n",
      "05/21/2022 11:40:57 - Global step: 1001, Loss: 0.26220872149588104\n",
      "05/21/2022 11:40:59 - Global step: 1002, Loss: 0.12445861499645616\n",
      "05/21/2022 11:41:02 - Global step: 1003, Loss: 0.04030386469094083\n",
      "05/21/2022 11:41:04 - Global step: 1004, Loss: 0.3891296851434163\n",
      "05/21/2022 11:41:06 - Global step: 1005, Loss: 0.06192539020412369\n",
      "05/21/2022 11:41:08 - Global step: 1006, Loss: 0.27023229593851283\n",
      "05/21/2022 11:41:11 - Global step: 1007, Loss: 0.08786815384519286\n",
      "05/21/2022 11:41:13 - Global step: 1008, Loss: 0.2280846638022922\n",
      "05/21/2022 11:41:15 - Global step: 1009, Loss: 0.011161505510244751\n",
      "05/21/2022 11:41:18 - Global step: 1010, Loss: 0.0113518044599914\n",
      "05/21/2022 11:41:20 - Global step: 1011, Loss: 0.28112723824960995\n",
      "05/21/2022 11:41:22 - Global step: 1012, Loss: 0.05417511679297604\n",
      "05/21/2022 11:41:24 - Global step: 1013, Loss: 0.06126041937022819\n",
      "05/21/2022 11:41:27 - Global step: 1014, Loss: 0.1340957865031669\n",
      "05/21/2022 11:41:29 - Global step: 1015, Loss: 0.4040539432753576\n",
      "05/21/2022 11:41:31 - Global step: 1016, Loss: 0.1586664153728634\n",
      "05/21/2022 11:41:34 - Global step: 1017, Loss: 0.01032391963963164\n",
      "05/21/2022 11:41:36 - Global step: 1018, Loss: 0.04204283642684459\n",
      "05/21/2022 11:41:38 - Global step: 1019, Loss: 0.1025946243898943\n",
      "05/21/2022 11:41:41 - Global step: 1020, Loss: 0.49345108999841614\n",
      "05/21/2022 11:41:43 - Global step: 1021, Loss: 0.1204221969255741\n",
      "05/21/2022 11:41:45 - Global step: 1022, Loss: 0.23663939346806728\n",
      "05/21/2022 11:41:48 - Global step: 1023, Loss: 0.14724376609228784\n",
      "05/21/2022 11:41:50 - Global step: 1024, Loss: 0.16211712531367084\n",
      "05/21/2022 11:41:52 - Global step: 1025, Loss: 0.3529459546552971\n",
      "05/21/2022 11:41:55 - Global step: 1026, Loss: 0.22276104064076208\n",
      "05/21/2022 11:41:57 - Global step: 1027, Loss: 0.14714081051351968\n",
      "05/21/2022 11:41:59 - Global step: 1028, Loss: 0.027127831446705386\n",
      "05/21/2022 11:42:01 - Global step: 1029, Loss: 0.4913393086171709\n",
      "05/21/2022 11:42:04 - Global step: 1030, Loss: 0.13029153887327993\n",
      "05/21/2022 11:42:06 - Global step: 1031, Loss: 0.025362536016473314\n",
      "05/21/2022 11:42:08 - Global step: 1032, Loss: 0.13028857304016128\n",
      "05/21/2022 11:42:11 - Global step: 1033, Loss: 0.2058781396917766\n",
      "05/21/2022 11:42:13 - Global step: 1034, Loss: 0.09071520810539369\n",
      "05/21/2022 11:42:15 - Global step: 1035, Loss: 0.12970294209662825\n",
      "05/21/2022 11:42:18 - Global step: 1036, Loss: 0.35045978384732734\n",
      "05/21/2022 11:42:20 - Global step: 1037, Loss: 0.10957704819156788\n",
      "05/21/2022 11:42:22 - Global step: 1038, Loss: 0.07030487159499899\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m training_data \u001b[38;5;241m=\u001b[39m data_obj\u001b[38;5;241m.\u001b[39mload_data_from_files(opts\u001b[38;5;241m.\u001b[39mtrain_file, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, debug\u001b[38;5;241m=\u001b[39mopts\u001b[38;5;241m.\u001b[39mdebug)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnetwork\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/tourqa/mymodel/TourQue_Exec.py:169\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(opts, data_obj, prep, network, training_data, test_data)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoss not configured: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mopts\u001b[38;5;241m.\u001b[39mloss\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    168\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss \u001b[38;5;241m/\u001b[39m opts\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps\n\u001b[0;32m--> 169\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m log_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m opts\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/tourqa/lib/python3.8/site-packages/torch/tensor.py:245\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    238\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    239\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    243\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    244\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 245\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tourqa/lib/python3.8/site-packages/torch/autograd/__init__.py:145\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    143\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m--> 145\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_data = data_obj.load_data_from_files(opts.train_file, training=True, debug=opts.debug)\n",
    "train(opts, data_obj, prep, network, training_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# opts.eval_type='std'\n",
    "# test_data = data_obj.load_data_from_files(opts.test_file, training=False, debug=opts.debug)\n",
    "# test(opts, data_obj, prep, network, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# opts.eval_type='random+'\n",
    "# test_data = data_obj.load_data_from_files(opts.test_file, training=False, debug=opts.debug)\n",
    "# test(opts, data_obj, prep, network, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# opts.eval_type='full'\n",
    "# test_data = data_obj.load_data_from_files(opts.test_file, training=False, debug=opts.debug)\n",
    "# test(opts, data_obj, prep, network, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance baseline\n",
    "\n",
    "05/16/2022 07:12:16 - Eval results on step-3 -- acc@1: 0.005555555555555556\n",
    "05/16/2022 07:12:16 - Eval results on step-3 -- acc@3: 0.016666666666666666\n",
    "05/16/2022 07:12:16 - Eval results on step-3 -- acc@5: 0.022222222222222223\n",
    "05/16/2022 07:12:16 - Eval results on step-3 -- acc@30: 0.11203703703703703\n",
    "05/16/2022 07:12:16 - Eval results on step-3 -- acc@100: 0.23333333333333334\n",
    "05/16/2022 07:12:16 - Eval results on step-3 -- acc@500: 0.537962962962963\n",
    "05/16/2022 07:12:16 - Eval results on step-3 -- mrr: 0.02186483412784222"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POI example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('../data/TourQue_Knowledge.json') as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "for k,v in data.items():\n",
    "    print(v)\n",
    "    for r in v['review']:\n",
    "        print('&',r.strip(),'\\\\\\\\')\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=torch.randn(4,500)\n",
    "b = torch.randn(4,500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0486,  0.0709, -0.0349, -0.0230])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.log_softmax(F.cosine_similarity(a, b, dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 24.0371]],\n",
       "\n",
       "        [[ 32.9524]],\n",
       "\n",
       "        [[-16.5039]],\n",
       "\n",
       "        [[-11.5589]]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.bmm(a.unsqueeze(1), b.unsqueeze(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bilinear_layer = nn.Bilinear(500, 500, 1)\n",
    "bilinear_layer(question_embeddings, entity_embeddings).reshape(2,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "from scipy.stats import mode\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['epoch','cuts','score'])\n",
    "data = []\n",
    "label = [0,2,4,6,8]\n",
    "cuts = [1,3,5,10,15,20,25,30]\n",
    "data.append(cuts)\n",
    "for epoch in label:\n",
    "    with open(f'../data/draw_fig/LOG_sp_33_hsp_32_bz_8_lr_2e-05_score_dot_loss_nll_name_True_loc_True_maxloc_5_dist_False_dw_0.5_haversine_False_seed_42_cluster_5_trainfile_train.json_testfile_test.json_distilbert-base-uncased__{epoch}_res.json') as f:\n",
    "        res = json.load(f)\n",
    "    pos = np.array(res['std_pos'])\n",
    "    for i in cuts:\n",
    "        score = np.sum(pos<i)/len(pos)\n",
    "        df = df.append({'epoch':int(epoch),'cuts':i,'score':score},ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['epoch'] = df['epoch'].astype('int64') +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>cuts</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.089178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.180678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.236414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.339062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.411054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.460752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.508128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.543892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.096609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.200186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.268463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.379935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.452856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.505806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.545286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.577334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.109614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.224338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.296795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.406410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.476080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.527171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>5</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.567580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.595913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.124477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.241988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.310265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.415235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>7</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.484905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>7</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.530423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>7</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.569902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>7</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.596842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.130051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.251277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.315374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>9</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.428704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>9</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.503019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>9</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.542963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>9</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.580585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>9</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.605667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  cuts     score\n",
       "0       1   1.0  0.089178\n",
       "1       1   3.0  0.180678\n",
       "2       1   5.0  0.236414\n",
       "3       1  10.0  0.339062\n",
       "4       1  15.0  0.411054\n",
       "5       1  20.0  0.460752\n",
       "6       1  25.0  0.508128\n",
       "7       1  30.0  0.543892\n",
       "8       3   1.0  0.096609\n",
       "9       3   3.0  0.200186\n",
       "10      3   5.0  0.268463\n",
       "11      3  10.0  0.379935\n",
       "12      3  15.0  0.452856\n",
       "13      3  20.0  0.505806\n",
       "14      3  25.0  0.545286\n",
       "15      3  30.0  0.577334\n",
       "16      5   1.0  0.109614\n",
       "17      5   3.0  0.224338\n",
       "18      5   5.0  0.296795\n",
       "19      5  10.0  0.406410\n",
       "20      5  15.0  0.476080\n",
       "21      5  20.0  0.527171\n",
       "22      5  25.0  0.567580\n",
       "23      5  30.0  0.595913\n",
       "24      7   1.0  0.124477\n",
       "25      7   3.0  0.241988\n",
       "26      7   5.0  0.310265\n",
       "27      7  10.0  0.415235\n",
       "28      7  15.0  0.484905\n",
       "29      7  20.0  0.530423\n",
       "30      7  25.0  0.569902\n",
       "31      7  30.0  0.596842\n",
       "32      9   1.0  0.130051\n",
       "33      9   3.0  0.251277\n",
       "34      9   5.0  0.315374\n",
       "35      9  10.0  0.428704\n",
       "36      9  15.0  0.503019\n",
       "37      9  20.0  0.542963\n",
       "38      9  25.0  0.580585\n",
       "39      9  30.0  0.605667"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 449.05x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#sn.set_style('ticks')\n",
    "sn.relplot(data=df, kind='line', x='cuts', y='score',hue='epoch', marker='+', dashes=True, height=4, aspect=1.4,palette=\"deep\")\n",
    "#plt.xlim(0, 100)\n",
    "#plt.ylim(0, 0.9)\n",
    "plt.xlabel(\"# of retrieved POIs\",fontsize=14)\n",
    "plt.ylabel(\"Top-k Accuracy\",fontsize=14)\n",
    "plt.savefig('../data/draw_fig/visualize_train.pdf',format='pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('../data/human_eval/LOG_sp_17_hsp_16_bz_8_lr_2e-05_score_dot_loss_nll_name_True_loc_True_maxloc_5_dist_True_dw_0.5_haversine_False_seed_42_cluster_5_trainfile_train.json_testfile_test.json_distilbert-base-uncased__0_prediction.json') as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "import random\n",
    "random.shuffle(data)\n",
    "r100 = data[:100]\n",
    "\n",
    "count = 0\n",
    "for piece in r100:\n",
    "    piece['human_eval_top3_hit'] = []\n",
    "    piece['prediction'] = piece['prediction'][:3]\n",
    "    for p in piece['prediction'][:3]:\n",
    "        if p in piece['all_answer_entity_list']:\n",
    "            piece['human_eval_top3_hit'] = [p]\n",
    "            \n",
    "# with open('../data/human_eval/random100_eval.json','w') as f:\n",
    "#     json.dump(r100,f,indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "with open('../data/human_eval/random100_eval.json') as f:\n",
    "    d = json.load(f)\n",
    "for p in d:\n",
    "    if p['human_eval_top3_hit'] != []:\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/TourQue_Knowledge_Cluster.json') as f:\n",
    "    knowledge = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'review': ['The place is a bit gloomy and old fashioned - like the clientele to be honest (us included).\\n',\n",
       "  'We have been coming here for years but it appears to be under new management now.\\n',\n",
       "  'Very traditional surroundings but just what we wanted.\\n',\n",
       "  'It was brilliant, the food was good and the service was great.\\n',\n",
       "  'I visited the restaurant with a friend for pre show dinner.\\n',\n",
       "  'On the night we went the service was uncoordinated with staff not watching the tables with some left alone for ages and others over attended.\\n',\n",
       "  'good food and a friendly waiter topped by a smiley cook more then enough to eat and a great enviroment.\\n',\n",
       "  'You no longer have to pre order food which is good but goodness me, the service was very stretched.\\n',\n",
       "  'It picked up soon however and the food (steamed Halibut) was divine.\\n',\n",
       "  'They appeared understaffed too which did not help.\\n',\n",
       "  'Have booked to go again!\\n',\n",
       "  \"At one point a member of the Front of House (it is in the ENO's London Coliseum) team was serving at table!\\n\",\n",
       "  'It has a very good and affordable wine list.\\n',\n",
       "  'A good wine list and not overpriced.\\n',\n",
       "  'Pudding and coffee can be taken in the (first, if more than one) interval if you wish, and they keep your table all night even if you have not asked for this, in case you need an interval \"top-up\", which is always a nice touch.\\n',\n",
       "  'Being able to enjoy cheese at our original table during the interval was brilliant, our wind was waiting for us and served immediately.\\n',\n",
       "  'We had sat our table for 15 mins without being offered bread or wine - we had to ask.\\n',\n",
       "  'Lets hope they sharpen up.\\n'],\n",
       " 'lat_long': [51.5104581, -0.1269445],\n",
       " 'name': \"America, 46 St. Martin's Lane, London WC2N 4EJ\",\n",
       " 'cluster_map': {'3': [1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 2, 1, 0, 2, 0, 1, 1, 2],\n",
       "  '5': [4, 2, 2, 2, 4, 1, 2, 2, 1, 4, 0, 3, 2, 0, 2, 1, 1, 0],\n",
       "  '7': [4, 2, 2, 2, 4, 0, 1, 2, 0, 6, 3, 5, 2, 3, 2, 0, 0, 1],\n",
       "  '9': [0, 1, 1, 1, 8, 0, 6, 1, 0, 3, 2, 4, 1, 2, 7, 5, 5, 6]}}"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knowledge['10_R_12190']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
